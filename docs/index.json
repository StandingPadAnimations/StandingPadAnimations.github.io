
[{"content":"","date":"26 September 2024","externalUrl":null,"permalink":"/tags/blender/","section":"Tags","summary":"","title":"Blender","type":"tags"},{"content":"","date":"26 September 2024","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"Note: there\u0026rsquo;s a lot of Mastodon embeds in this post.\nLate last year, I made a post (or toot I guess?) on Mastodon showing a test of a custom rig I was working on.\nAnd about a day later created what would be the first render I made utilizing this rig for the first time\n","date":"26 September 2024","externalUrl":null,"permalink":"/posts/2024/09/releasing-my-custom-rig/","section":"Posts","summary":"","title":"Releasing My Custom Rig","type":"posts"},{"content":"","date":"26 September 2024","externalUrl":null,"permalink":"/","section":"StandingPad's Corner","summary":"","title":"StandingPad's Corner","type":"page"},{"content":"","date":"26 September 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" Recently I decided to try something new and try to composite together some Minecraft stuff in real world photography. After a lot of work and sorcery, here\u0026rsquo;s the results I came up with. I\u0026rsquo;ll just talk about what I discovered while working on this, so this won\u0026rsquo;t be a tutorial. That said, this should still be interesting to anyone looking to try and do the same thing.\nLighting # For this project, I started with this image from Pexels. Big mistake, don\u0026rsquo;t use random images when doing something like this. The issue is you then have to go through pain in order to replicate the lighting in the image. Please, for the purposes of simplicity, use an HDRI backplate as the image you\u0026rsquo;ll be compositing to, it\u0026rsquo;ll be way easier as you can just use the HDRI on its own. In addition, JPEGs don\u0026rsquo;t make for good HDRIs out of the box. I had to use 2 trick s to get this to work:\nFlipping Invert colorspace transforms Flipping is easy, just mirroring the image across one axis, colorspace is the harder part. In Blender, one can inverse the OCIO transforms of an image to make a random image into a (very approximate) HDR. I\u0026rsquo;m not an expert, so I\u0026rsquo;ll just copy and paste a conversation I had with someone who is:\nMe: But how does that work, I doubt the image uses AgX itself\nPedro: The important part is that it\u0026rsquo;s the exact inverse operation of the tonemaper, so if you chain the linearization-\u0026gt;tonamep operations, it looks like absolutely nothing has changed.\nPedro: You\u0026rsquo;re right though, the image didn\u0026rsquo;t use AgX. The linearization step is a very rough approximation, based on the assumption that most photos will have had similar operations applied: Highlight compression, gamma encoding, a bit of contrast applied. That approximation is enough in most cases\nMe: So basically it makes the JPEG not subject to tonemapping by Blender?\nPedro: A better way to put it would be that the final image looks like the starting image. The linearization is done when the image is loaded, and any operation done by the renderer (like casting emissive lighting) will benefit from more accurate values\nIn fancy terms, it makes images look how they started, which allows them to act like HDR images. To do this in Blender, you just set the colorspace on the image texture in the nodetree. The important thing is the colorspace must match the view transform you are using in Blender. If you\u0026rsquo;re using Filmic, set it to Filmic; if you\u0026rsquo;re using AgX, set it to AgX, etc.\nCatching Shadows and De-lighting Textures # Now we need to catch shadows in our scene. However, there is one piece of info I don\u0026rsquo;t see being talked about a lot: The material of the shadow catcher will still affect how objects interact with it, lighting wise. That means we can\u0026rsquo;t just leave our shadow catcher be, we have to use the texture, and it has to be a shader output too (in order for shadows to work), not a color output. That however causes the following issue: The ball is reflecting a purplish tint from the shadow catcher, which doesn\u0026rsquo;t match the ground in the actual image. If we uncheck the shadow catcher setting, we see why this happens: The shader on the shadow catcher doesn\u0026rsquo;t have the proper color on the texture. It\u0026rsquo;s catching the purple-tinted light from the environment lighting. Therefore, we must go through a complex, overly complicated, exclusive to Blender solution called de-lighting. It\u0026rsquo;s as scary as it sounds. This video does a good job at explaining it, and I\u0026rsquo;ll summarize their summary for those that don\u0026rsquo;t want to watch it (watch it though, it\u0026rsquo;s extremely useful) In a nutshell, if this is how our shadow catcher interacts with the HDRI (where \\(I\\) is the image\u0026rsquo;s lighting, \\(S\\) is the lighting in the 3D scene replicating the image, and \\(R\\) is the result): $$ I * S = R $$\nIn order for the result to look like the texture itself, we need to divide the image by the lighting in the scene that is used to replicate the lighting in the image:\n$$ \\dfrac{I}{S} * S = R $$\nWhich cancels out the scene lighting (\\(S\\)), and makes \\(R\\) be the texture itself, as if the texture was directly connected to the shader output, but now able to catch shadows. Or to show what it looks like: For this, I just used the Compify addon for simplicity, but the video above (which again, I highly recommend watching) also explains how to do it manually (tldr: bake the scene lighting on a pure white, diffuse material to a texture, and divide the original texture by the baked lighting in a Mix node, and plug the result into a diffuse BSDF)\nMatching Exposure # Out of the box, the brightness of the rendered image will not match the brightness of the image we\u0026rsquo;re compositing on. To solve this, we need to adjust the exposure of the render.\nHowever just eyeballing is not enough, we need the brightness to absolutely match. This is where False Color helps. For example, as we can see with false color here, the character is darker then the path she\u0026rsquo;s walking on: With this, we can then correctly expose the image so that in false color, the character\u0026rsquo;s brightness matches the brightness of the path. That\u0026rsquo;s pretty much all of the stuff I discovered along of the way of making this. Cya!\n","date":"20 September 2024","externalUrl":null,"permalink":"/posts/2024/09/compositing-minecraft-characters-in-images/","section":"Posts","summary":"","title":"Compositing Minecraft Characters in Images","type":"posts"},{"content":"A lot of times on Blender communities, I\u0026rsquo;ll get DMs from people wanting support for their issue. I\u0026rsquo;m not sure why me specifically (I\u0026rsquo;m a Minecraft artist), but it happens, and usually goes something like this:\nPerson 1: Bro please help me with this issue So I\u0026rsquo;ll say it here: please don\u0026rsquo;t DM me for support, I\u0026rsquo;m probably going to ignore it. If it\u0026rsquo;s a matter that absolutely needs my attention, and you don\u0026rsquo;t want to tag me publicly on a server (which I would prefer), your best route is to email me (also on the home page of my website). Unlike DMs on platforms like Discord, emails are easier for me to archive and keep a paper trail of what comes through. Plus, I check my emails everyday.\nOf source, some might ask \u0026ldquo;if you don\u0026rsquo;t like DMs so much, why have them enabled?\u0026rdquo;. I actually used to keep them closed, but that became very annoying in the long run. Sadly, platforms like Discord are all or nothing when it comes to DMs on a per-server basis, so keeping DMs closed is just impractical for me.\nTldr: please don\u0026rsquo;t DM me if you need Blender support, either tag me publicly on a server or email me privately if absolutely necessary.\n","date":"30 August 2024","externalUrl":null,"permalink":"/posts/2024/08/dont-dm-me-for-support/","section":"Posts","summary":"","title":"Don't DM Me for Support","type":"posts"},{"content":"","date":"30 August 2024","externalUrl":null,"permalink":"/tags/irl/","section":"Tags","summary":"","title":"IRL","type":"tags"},{"content":"tldr: Learn to step back for a little bit when you feel your art is crap\nOver the past few years, I\u0026rsquo;ve seen many artists come and go in the Minecraft rendering community, and there\u0026rsquo;s one thing said that seems to be constant:\nThis sucks.\nPretty much every artist at some point will say this with regards to their own art, especially when they start to start looking at other artists of varying skill sets, and to be honest, it\u0026rsquo;s fricking annoying, so I\u0026rsquo;ll say this:\nTake a step back. Seriously, take a step back for a few hours from your art and come back later. Trust me, it\u0026rsquo;ll help a lot.\nI call this the Good Shit Law (excuse the language for just a moment):\nWhat looks shit now will look good with fresh eyes.\nNow why did I make this? Well because recently I took a second look at something I made back in July that I thought was absolutely garbage, and you know what, it didn\u0026rsquo;t look as bad as I thought it was back then.\nI was originally going to present it as an option for the MCprep 3.6 release artwork, but at the time decided that it was garbage and thus scrapped it (it was also 1 AM). However, taking a second look at it, I think it looks decent enough to post online now.\nThat\u0026rsquo;s pretty much all I wanted to write this time around, cya!\n","date":"16 August 2024","externalUrl":null,"permalink":"/posts/2024/08/advice-for-new-artists/","section":"Posts","summary":"","title":"Advice for New Artists","type":"posts"},{"content":"","date":"16 August 2024","externalUrl":null,"permalink":"/tags/art/","section":"Tags","summary":"","title":"Art","type":"tags"},{"content":"","date":"28 July 2024","externalUrl":null,"permalink":"/tags/mcprep/","section":"Tags","summary":"","title":"MCprep","type":"tags"},{"content":"I know, I know, a lot of people hate how we\u0026rsquo;ve become strict with bug report templates on the MCprep repo, especially in the past, we might have been a lot more forgiving with bug reports. I think it\u0026rsquo;s best if I explain why we need to be so strict with using the proper template for bug reports.\nThe Problem # One of the biggest issues we\u0026rsquo;ve had (and still do some degree in some areas) is the lack of useful information in bug reports. What defines useful information? For MCprep development, useful information is the following:\nDetailed description of the problem (with screenshots!) MCprep and Blender versions Steps to reproduce the issue (biggest thing!) However, in the past, a good chunk of bug reports in MCprep would be some variation of the following:\nUser: Hi I have an issue Us: Ok, what is the issue? Can you elaborate further or share a screenshot? silence\u0026hellip;\nThis caused several issues for us developers, including but not limited to:\nBack and forth over several days, weeks, even months, just to get useful information Unable to gather more info due to users ghosting us after the initial report (since most don\u0026rsquo;t use GitHub beyond just making a single bug report) This still occurs somewhat with asset submissions, leading us to introduce a requirement that rig submitters must be active in the discussion, or risk their submission being rejected Bug reports that, after much effort, turn out to be user error (mostly due to ignoring updates), unnecessarily clogging the bug tracker for a long time Inability to reproduce bugs on our end due to poor descriptions with little to no steps to reproduce Built-in Reports # \u0026ldquo;But what about those reports we send in Blender itself\u0026rdquo; I hear some of you say. Sure, MCprep has built-in reports, but this is what they look like: Ignoring the fact that this is not even accessible to most developers beyond us maintainers 1, it\u0026rsquo;s also just extremely hard to use, especially as all of the comments are just horrible for reproducing information. Here\u0026rsquo;s some examples:\n\u0026ldquo;iron\u0026rdquo; \u0026ldquo;pls\u0026rdquo; \u0026ldquo;1\u0026rdquo; \u0026ldquo;CRAP YOU\u0026rdquo; (yes, this is a real comment made from someone on June 24th, 2024) \u0026ldquo;dawg imma be fr wit chu dw bout this my blender addons jus fr keep breaking\u0026rdquo; (if you\u0026rsquo;re the user that made this comment, just know that you were also using MCprep 3.4.3. You\u0026rsquo;re behind by like 3 versions) \u0026ldquo;3\u0026rdquo; \u0026ldquo;4\u0026rdquo; \u0026ldquo;dream\u0026rdquo; From this assortment of comments, 2 things are clear: 1. that clearly I should compile a list of the funniest comments from the built-in tracker (seriously, who doesn\u0026rsquo;t want to read stuff like this on a slow day?), but more importantly 2. the comments from the built-in tracker are useless. Sure, there\u0026rsquo;s some useful info, and a minority of users are actually decent and explain what they were doing, but the keyword is minority.\nThis isn\u0026rsquo;t to say we don\u0026rsquo;t use the built-in tracker, but these days, it\u0026rsquo;s mainly a second source of information for known bugs if we want to determine how widespread something is. For example, we used it to determine how widespread a bug in textureswap was after the release of MCprep 3.5.2. Other then that though, it\u0026rsquo;s mostly useless for regular development.\nHere Comes the Templates # We found that the only way to get more information from bug reports was to make said information a requirement when filing them out. GitHub makes this easy with Issue Templates. By adding fields for certain pieces of info, we\u0026rsquo;ve effectively made most bug reports much easier to reproduce and debug, or quicker to close if the issue is not a bug. There are exceptions of course since some people just don\u0026rsquo;t follow instructions (see #558), but I estimate that, when counting all of the hours saved from pain and agony, we\u0026rsquo;ve saved several years worth of time and energy with bug reports as a whole. That\u0026rsquo;s why we\u0026rsquo;re extremely strict about using bug report templates, they save a lot of time and effort with debugging. 2\nSo please, just use the bug report template and fill it out correctly the first time.\nTo be specific, as far as I\u0026rsquo;m aware, built-in reports are only accessible to TheDuckCow and myself\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThere is only one time reports that don\u0026rsquo;t use the template are accepted: if they\u0026rsquo;re opened by maintainers, but even then we use the bug report and feature request templates unless they hinder in our ability to describe what we\u0026rsquo;re opening a GitHub Issue on\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 July 2024","externalUrl":null,"permalink":"/posts/2024/07/why-were-strict-with-bug-report-templates/","section":"Posts","summary":"","title":"Why We're Strict With Bug Report Templates","type":"posts"},{"content":"As the title suggests, I have decided to take a vow of silence IRL. I have reasons, but I don\u0026rsquo;t think it\u0026rsquo;s important to delve into those here.\nFor interactions on the internet, this doesn\u0026rsquo;t change much, beyond MCprep developer meetings.\nI haven\u0026rsquo;t decided when I\u0026rsquo;ll end it; a month, half a year, a year, or perhaps longer? I don\u0026rsquo;t know.\nThat\u0026rsquo;s all I have, cya.\n","date":"30 June 2024","externalUrl":null,"permalink":"/posts/2024/06/vow-of-silence/","section":"Posts","summary":"","title":"Vow of Silence","type":"posts"},{"content":"","date":"22 June 2024","externalUrl":null,"permalink":"/tags/affinity/","section":"Tags","summary":"","title":"Affinity","type":"tags"},{"content":" Recently I've been playing around with recompositing some of my older pieces in Affinity Photo for learning purposes. This page will get updated as I continue with further recompositing. Old version is on the left, the Affinity recomposited version is on the right.\nOld Recomposited ","date":"22 June 2024","externalUrl":null,"permalink":"/posts/2024/06/affinity-recompositing/","section":"Posts","summary":"","title":"Affinity Recompositing","type":"posts"},{"content":"Yes, you heard that right, I got Affinity Photo and Designer working on Linux\nHere\u0026rsquo;s a write-up explaining how I did it, using Bottles\nSome Important Info: # If you have Affinity 1, this is mostly unnecessary (except maybe Bottles setup), since Upstream WINE supports most releases of Affinity 1. Later versions (1.10.3 and above) might be a bit of a hit or miss though, since Serif changed their license manager at some point, and it requires some files from Windows (see WinMD for instructions on how to set that up)\nMuch of this comes from Wanesty\u0026rsquo;s guide. If you discover any fixes, please comment those fixes on the repo. That said, Wanesty\u0026rsquo;s guide uses Rum to manage prefixes, whereas we\u0026rsquo;re using Bottles (just a personal preference on my part).\nCompatibility wise, this should work with Affinity 2.5 (the latest release) Wanesty\u0026rsquo;s repo also has a Tips and Fixes section if you come across some issues. There are still many known problems with Affinity on WINE that have not yet been solved, such as user preferences not saving. That said, at least in the past few days, Affinity has worked pretty well on Linux\nFor those saying \u0026ldquo;Why use Affinity instead of Free Software?\u0026rdquo;, I\u0026rsquo;ll say this (and this will be a hot take): I run Linux for choice, and that includes the choice of using whatever software I want. If you don\u0026rsquo;t want to run Affinity at all, that\u0026rsquo;s fine, but don\u0026rsquo;t act like you\u0026rsquo;re somehow morally superior as a result. Many people (myself included) prefer Affinity over free software alternatives, whether it be personal preference or absolute necessity (I\u0026rsquo;m looking at you GIMP and your lack of multi-layer EXR support). If you\u0026rsquo;ve never had any issues, good for you, but that doesn\u0026rsquo;t mean they don\u0026rsquo;t exist.\nAnyway, here\u0026rsquo;s a basic overview of what I did to get Affinity to work.\nWINE # For Affinity 2, upstream WINE doesn\u0026rsquo;t support the necessary functions needed.\nThankfully, ElementalWarrior has created some patches to get Affinity to work on WINE 1, which we\u0026rsquo;ll be using to get Affinity working on Linux\nI don\u0026rsquo;t know about y\u0026rsquo;all, but I don\u0026rsquo;t really want to install all of the build dependencies on my system. In addition, you might have issues if you\u0026rsquo;re on a more stable distro. Thankfully, someone has made a Podman container (you can also use Docker if you wish) to build WINE from source without impacting the main system.\nSo first we need to clone ElementalWarrior\u0026rsquo;s patches. We only need the affinity-photo3-wine9.13-part3 branch, so to save time, we can simply do the following:\ngit clone https://gitlab.winehq.org/ElementalWarrior/wine.git ElementalWarrior-wine -b affinity-photo3-wine9.13-part3 Next we need to cd into repo and run the wine-builder container. I\u0026rsquo;ll be using Podman since that\u0026rsquo;s what the container was designed for, but you can also use Docker\npodman run -v ./:/wine-builder/wine-src wine-builder This will take a while, so find something else to do in the meantime.\nBottles # Now we need to create a Bottle for Affinity. I\u0026rsquo;m assuming y\u0026rsquo;all know the basics of using Bottles and running executables with it (as well as installing dependencies), so I\u0026rsquo;ll simply give a basic overview.\nFirst, copy the built WINE to the runners directory for Bottles. This can either be $HOME/.local/share/bottles/bottles/runners (if installed natively) or $HOME/.var/app/com.usebottles.bottles/bottles/runners (if installed as a Flatpak). The built WINE should exist in a wine-install folder.\ncp -r path/to/ElementalWarrior-wine/wine-install/ path/to/bottles/runners/ElementalWarrior-9.3 Create a new bottle for Affinity, and with it, set the following under Settings:\nComponents \u0026gt; Runner: ElementalWarrior-9.3 Components \u0026gt; DXVK: Disabled Components \u0026gt; VKD3D: Disabled Display \u0026gt; Advanced Display Settings \u0026gt; Renderer: Vulcan Compatibility \u0026gt; Windows Version: Windows 10 Next, install the following dependencies:\nallfonts dotnet35 dotnet48 mono vcredist2015 2 WinMetadata Files # Before we can run the Affinity installer, we need to copy some files from a Windows install. Not a Window install of Affinity, but the actual install of Windows itself. To do this, on Windows, copy C:/windows/system32/WinMetadata somewhere that you can access on Linux, and then copy those files to your Affinity bottle. 3\ncp -r path/to/WinMetadata path/to/bottles/bottles/[bottle-name]/drive_c/windows/system32/WinMetadata Preferences # One issue with Affinity on Linux is that preferences don\u0026rsquo;t save properly, and no one knows why. The best option for now is to set important preferences (like OCIO config) on Windows, bring the config over from AppData/Roaming to the WINE bottle, and then change the XML as needed for any paths. Not ideal, but better then nothing.\nWith all of that done, you can now run the installer for any Affinity product! Like I said earlier, check out Wanesty\u0026rsquo;s repo if you come across any issues, as this guide is simply an Bottles adaption of her guide.\nEnjoy!\nFootnote for transparency: This tutorial used to use the ElementalWarrior fork of WINE 8.14, then Lukas Magauer rebased those patches for WINE 9.12. Finally, ElementalWarrior updated the patches to WINE 9.3. Yeah welcome to WINE development.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI\u0026rsquo;ve heard this can cause some issues with crashing, and Wanesty has removed it from her guide as a result. I\u0026rsquo;m keeping it here since it helps with export bugs, but do be aware of that.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFor legal reasons, I cannot distribute these files.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"22 June 2024","externalUrl":null,"permalink":"/posts/2024/06/affinity-on-linux/","section":"Posts","summary":"","title":"Affinity on Linux","type":"posts"},{"content":"Yep, I got hired for an paid summer internship at VLK Architects (A local architecture firm in Texas specializing in designing spaces for K-12 education) and will be starting Monday June 10th. This is my first 3D related job, and (from what I\u0026rsquo;ve been told) will heavily involve Unreal Engine.\n(Yes, I was surprised too, but it makes sense given the massive new features in UE 5)\nHip hip hurray!\n","date":"8 June 2024","externalUrl":null,"permalink":"/posts/2024/06/i-got-hired-at-vlk/","section":"Posts","summary":"","title":"I Got Hired at VLK","type":"posts"},{"content":"Yep, a new Vivy addon will be made. Here\u0026rsquo;s why and how.\nThe Rationale # For those that don\u0026rsquo;t know, Vivy is a fork of MCprep I made to give myself more control with the materials that MCprep generates. For the most part, it has succeeded, but as an MCprep fork, it\u0026rsquo;s a headache to maintain.\nMCprep goes through a lot of changes per update (admittedly, a lot of that is my fault, as I\u0026rsquo;m also a MCprep developer, and a lot of architectural changes come from me), which makes Vivy a hell to maintain. In addition, MCprep is also thousands of lines of code (17,000 as I write this), and while in theory an individual could make and maintain a fork, I have my plate full with MCprep already, so Vivy doesn\u0026rsquo;t get the time it needs to be properly maintained. Ideally, one would be able to install both side-by-side, but that\u0026rsquo;s not possible as conflicts would occur with registered classes.\nAnother reason is changes with Vivy that are better off getting a rewrite. Vivy Components was created to abstract much of the raw JSON parsing and handling for Vivy, but using it would require a full rewrite of the Vivy system anyway. In addition, I also want to change ow Vivy as a whole works, and I figure it will be more productive to just make a new addon.\nThe How # Firstly, the old Vivy repo will be archived, and eventually a new Vivy2 repo will be created. It should be noted that none of this will affect the planned date for this year\u0026rsquo;s Summer piece, since that won\u0026rsquo;t rely on Vivy. That being said, the December piece will rely on Vivy, so we\u0026rsquo;re starting early.\nThe entire way Vivy will operate will be changed. I\u0026rsquo;ll go more in detail once I get Vivy2 out, but in short, all materials will be stored in a tree hierarchy, over the current\u0026hellip; idk what to call it. This config will be managed with nodes using Blender\u0026rsquo;s custom nodetree API, but again, more on that in the future.\nUnlike the current Vivy, Vivy2 will be made with public use in mind. No more of having to wait for me to write documentation on how to use Vivy (if future me keeps my word on that\u0026hellip;).\nYeah, that\u0026rsquo;s pretty much it. It\u0026rsquo;s a bit of a messy post, since I wanted to get this out quickly. Cya!\n","date":"3 May 2024","externalUrl":null,"permalink":"/posts/2024/05/plans-for-a-new-vivy-addon/","section":"Posts","summary":"","title":"Plans for a New Vivy Addon","type":"posts"},{"content":"","date":"3 May 2024","externalUrl":null,"permalink":"/tags/vivy/","section":"Tags","summary":"","title":"Vivy","type":"tags"},{"content":"","date":"28 April 2024","externalUrl":null,"permalink":"/tags/bforartists/","section":"Tags","summary":"","title":"Bforartists","type":"tags"},{"content":"Yep, you heard that right, the Bforartists Flatpak is now official\u0026hellip; because I\u0026rsquo;ve returned to the Bforartists development team :tada:\nA bit of historical context for those unaware, the Bforartists Flatpak was, although endorsed, technically considered unofficial due to some conflicts between upstream and I (which I take full responsibility for). Although there was still some level of coordination between myself and the Bforartists team for packaging, the Flatpak still operated independently from the main project. This has been the general state of the Bforartists Flatpak for about a year now.\nAbout a week ago (to clear my conscious), I sent a short letter to the Bforartists team apologizing for the issues I caused in the past. In response, I was allowed back on the Bforartists team, making the Flatpak officially supported. This brings a couple of changes:\nThe Bforartists issue tracker will now be used for the Flatpak instead of the Flathub repo The Flathub listing for Bforartists will now say \u0026ldquo;Bforartists\u0026rdquo; as the author (verification is planned as well) In the future, I plan to eventually take over packaging for Bforartists on Linux in general, once I get powerful enough hardware (namely RAM) for compiling Bforartists.\nCya!\n","date":"28 April 2024","externalUrl":null,"permalink":"/posts/2024/04/bfa-flatpak-made-official/","section":"Posts","summary":"","title":"Bforartists Flatpak Made Official","type":"posts"},{"content":"A while back I announced Vivy, the in-house fork of MCprep with an overhauled material system that gives more control to the user. At the time, I stated I wasn\u0026rsquo;t interested in making it a full fork of MCprep for the public as Vivy has a higher learning curve then MCprep when it comes to using. Well I\u0026rsquo;ve thought about it a little more and have decided to make it a full fork.\nThings that Need to be Done # To make Vivy a full fork however, a lot of things need to be done.\nCode Side # For starters, Vivy\u0026rsquo;s material system needs to be properly integrated in the rest of the codebase. Right now, Vivy\u0026rsquo;s material system uses seperate operators for everything material related, to avoid breaking other parts of MCprep such as spawners. However, to make Vivy a proper fork, we\u0026rsquo;d need to properly redo the main MCprep operators.\nOne issue in Vivy\u0026rsquo;s current system is that it uses raw JSON everywhere, which tends to make things messy. This was mostly due to sheer laziness on my part with wanting to get something that works, but that\u0026rsquo;s not acceptable if we want to make Vivy a full public fork. To help with this, Vivy\u0026rsquo;s material system have been split into 2 parts: the Vivy operators in the GNU GPL licensed addon, and JSON parsing + \u0026ldquo;Independent Operations\u0026rdquo; (operations that don\u0026rsquo;t depend on Blender). The latter part is now on its own repository, under a more permissive BSD 3-Clause license called Vivy Components.\nStandingPadAnimations/Vivy-Components Vivy material components split from the Vivy addon, independent of Blender Python 0 0 Vivy Components will also help with one area Vivy has sorely been lacking in, UX.\nDocumentation # Vivy is an addon with a high learning curve. Out of the box, there\u0026rsquo;s nothing; prep materials won\u0026rsquo;t work, textureswap won\u0026rsquo;t work, etc. Although some people have managed to figure out how to use Vivy by just looking at the Mastodon posts I made on Vivy, this isn\u0026rsquo;t ideal as it only gives a bare minimum amount of information needed to use Vivy; Vivy as a system is highly complex, and should be learned in full for users to take advantage of. This is where GitHub Wikis becomes useful.\nUpstream # On the MCprep Discord, I\u0026rsquo;ve said in a couple of places that I\u0026rsquo;m thinking of implementing Vivy\u0026rsquo;s material system in MCprep directly. Well, that won\u0026rsquo;t be happening in the near future. The primary reason goes back to the high learning curve, but also some design decisions in MCprep that conflict with Vivy: MCprep is designed to be as simple as possible, and to do as much heavy lifting as possible. Vivy by contrast is the opposite, giving the user far more control in many areas while not being as simple. As such, it\u0026rsquo;s better in the long run if Vivy continues to remain separate from MCprep (although both Vivy and Vivy Components are open source, in case someone wants to do that).\nI can\u0026rsquo;t give an exact timeline of when all of this will be done, other than \u0026ldquo;by my 2024 Summer Piece\u0026rdquo; (see here for what I mean). Currently I\u0026rsquo;m also working on MCprep for the MCprep 3.6 update, and IRL I also have school to be concerned about. If anyone wants to contribute to Vivy, go ahead, it would be appreciated.\nStandingPadAnimations/Vivy MCprep with 100% more control! Python 0 0 Cya!\n","date":"31 March 2024","externalUrl":null,"permalink":"/posts/2024/03/next-step-with-vivy/","section":"Posts","summary":"","title":"The Next Step with Vivy","type":"posts"},{"content":"","date":"28 March 2024","externalUrl":null,"permalink":"/tags/commonmcobj/","section":"Tags","summary":"","title":"CommonMCOBJ","type":"tags"},{"content":"","date":"28 March 2024","externalUrl":null,"permalink":"/tags/minecraft-rendering/","section":"Tags","summary":"","title":"Minecraft Rendering","type":"tags"},{"content":"It\u0026rsquo;s been a while, and the past month has been a bit interesting. From Ramadan starting to CommonMCOBJ, there\u0026rsquo;s simply a lot I should have written about in the past, so I\u0026rsquo;m creating this giant megapost. Enjoy!\nAlso, the phrase \u0026ldquo;This Month\u0026rsquo;s Standing\u0026rdquo; is completely intentional lol\nRamadan # This year Ramadan began around March 10th where I live 12, and so far it\u0026rsquo;s going great.\nI wanted to create a special theme for this website for Ramadan or Eid (based on a post of some ideas for personal websites), but let\u0026rsquo;s just say calculating when Ramadan and Eid occur in JS is\u0026hellip; non-existent if you want something accurate, so alas, no custom theming :c.\nAs a quick aside, I also had my second SAT (school issued) this month; haven\u0026rsquo;t gotten my scores back though.\nCommonMCOBJ # One of the highlights of the past month is CommonMCOBJ, which aims to create a standard specification for exporting extra metadata that OBJ exporters previously didn\u0026rsquo;t export. It\u0026rsquo;s bare-bones currently, but we plan to add more parts such as biome exports to get accurate colors for grass and leaves.\nAs part of CommonMCOBJ, I had to crack my knuckles a bit and learn Kotlin + Java to create cmc2OBJ (forked from jmc2OBJ), which serves as the reference implementation for CommonMCOBJ.\nAs of writing, Mineways has just implemented support in the latest beta (and plans to get it out soon), and jmc2OBJ has a separate branch implementing CommonMCOBJ. MCprep is also working towards reading and parsing CommonMCOBJ data to push adoption.\nLighting Series # One of the things I want to work on is rewriting the lighting series. Put it simply, I hate it, I absolutely hate it. The writing is bad, it\u0026rsquo;s too much of a step-by-step tutorial rather then actually teaching lighting, and I\u0026rsquo;m just not a fan. I think a lot of it boils down to simply it originally being a PDF file and thus me having to complete the full thing before pushing it. Now that I can put it here, I can work on it over a longer period of time.\nBefore I rewrite the whole series though, I have an idea for a \u0026ldquo;catalog of lighting\u0026rdquo;, where different lighting options are showcased as a quick reference for artists, all with the same main subject(s) (currently, I\u0026rsquo;m thinking of using the Minecraft build, \u0026ldquo;The Uncensored Library\u0026rdquo;, as it just has so much opportunity). It\u0026rsquo;ll be quite a bit of time before I start working on that though.\nA bit off topic, but I also want to continue my Cycles optimization series (which I haven\u0026rsquo;t updated in over a year now), since there does seem to be some traffic coming to those pages. I have a couple of ideas on what to cover next\u0026hellip;\nSome Other Things # I\u0026rsquo;ve moved from Hyprland to KDE Plasma 6 as my main desktop now, but I feel that deserves its own article.\nThe past month or 2 I\u0026rsquo;ve also been using Feedbin for my RSS feeds and newsletters. I\u0026rsquo;m like it, it\u0026rsquo;s convenient and simple to use. Although it\u0026rsquo;s a monthly subscription, it\u0026rsquo;s only $5 and the free trial is about a month too. Plus, it\u0026rsquo;s open source, and I do like a good open source project.\nSpeaking of stuff I\u0026rsquo;ve been trying, I\u0026rsquo;ve also been trying out Kagi, but I\u0026rsquo;ve only been using it for a short time so I can\u0026rsquo;t give any opinions yet (not that I want to turn the rest of this post into a product review, I think those deserve their own posts).\nI\u0026rsquo;ve applied for an ArchViz internship at a local architecture company, hope it goes well! As an interesting tidbit, the person who interviewed me mentioned that they use Blender and Unreal Engine, which sounds fun.\nJust today I\u0026rsquo;ve been looking into a somewhat dead project called Plan 9, which is a research OS created at Bell Labs in the 90s with the main developers of the original UNIX operating system. From what I\u0026rsquo;ve found, a lot of the commands in Plan 9 such as mk (the Plan 9 version of make) are apparently cleaner and improved from their original UNIX versions, but I\u0026rsquo;m more focused on the mascot: Come on, this is peak mascot design, I\u0026rsquo;m really tempted to set this as my profile picture on the internet now. If Plan 9 was a desktop system with good support, this mascot alone would convince me to jump from Arch. Also I really like old style plain HTML websites like this: Honestly part of me wishes I had started with that since the beginning, but oh well. Maybe future me can do that, although that would be a massive pain.\nThat\u0026rsquo;s pretty much all I have this month; hopefully I remember to start writing more. Cya!\nIt\u0026rsquo;s a long story but the short answer is that the Islamic calendar is not globally in the same way the Gregorian calendar is, but rather is based on the lunar cycle in one\u0026rsquo;s local region. As an aside, the Islamic calendar typically moves 11 days earlier in the year relative to the Gregorian calendar, so we\u0026rsquo;re going to have Ramadan during winter in good a couple of years.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nAlso this year, Ramadan and Lent coincide with each other!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 March 2024","externalUrl":null,"permalink":"/posts/2024/03/this-months-shenanigans/","section":"Posts","summary":"","title":"This Month's Standing: March 2024","type":"posts"},{"content":"","date":"28 March 2024","externalUrl":null,"permalink":"/tags/website/","section":"Tags","summary":"","title":"Website","type":"tags"},{"content":"Hey y\u0026rsquo;all, it\u0026rsquo;s been a while since my last website update (beyond a couple of changes to the background image). This update comes with 2 things:\nAnalytics to track page views Removal of comments For analytics, we\u0026rsquo;re tracking page views through GoatCounter, which is open source. More info can be found on the privacy policy for this website, but the tldr is that no personally identifiable information (that could be traced back to an individual) is collected. The reason I\u0026rsquo;m implementing analytics is to get an idea of what people actually want to read, so maintaining this website doesn\u0026rsquo;t end up being boring.\nAs for comments, they\u0026rsquo;re being removed because no one used them, and there\u0026rsquo;s no real point to them.\nThat\u0026rsquo;s all I have, cya!\n","date":"14 January 2024","externalUrl":null,"permalink":"/posts/2024/01/analytics/","section":"Posts","summary":"","title":"Adding Analytics and Other Changes","type":"posts"},{"content":"I\u0026rsquo;m proud to announce a new addon called Estella, which aims to improve working with light linking and light groups.\nAs we know, Blender\u0026rsquo;s light linking UI isn\u0026rsquo;t really the best, as it requires selecting lights individually. That might be ok for a small scene, but what about a large scene with tons of lights? That\u0026rsquo;s where Estella really shines.\nThe light linking UI for Estella is based on Maya\u0026rsquo;s UI, which does light linking extremely well. In the future, Estella will also implement a object centric UI for light linking, which Blender does not provide.\nEstella also improves light groups by providing features that Blender doesn\u0026rsquo;t. This includes:\nIsolating light groups Renaming light groups Toggling visibility for light groups etc Through this, Estella is able to turn light groups from a clunky to an absolute joy to use. Estella\u0026rsquo;s GitHub repo and first release can be found below, cheers! StandingPadAnimations/Estella Streamline working with light groups and linking! Python 1 0 Download Estella 1.0 ","date":"14 January 2024","externalUrl":null,"permalink":"/posts/2024/01/estalla-first-release/","section":"Posts","summary":"","title":"Introducing Estella","type":"posts"},{"content":"It\u0026rsquo;s almost New Year\u0026rsquo;s, so you know what that means! Another New Year\u0026rsquo;s render to finish out the year!\n\u0026ldquo;But Mahid, it\u0026rsquo;s Christma-\u0026rdquo; pulls out gun They\u0026rsquo;re close enough.\nBut first some life updates to go through (ugh, I know). If you want to skip all of this, then click the button.\nSkip As it might have been quite obvious over the last year, I\u0026rsquo;ve not been making many pieces, and I\u0026rsquo;ve started to break down the wall between my real world life and the digital world. I\u0026rsquo;ll get to the former a bit later, but the latter might need a bit of explaining.\nBring down the Wall! # For several years, I\u0026rsquo;ve been a believer in trying to keep one\u0026rsquo;s digital life seperate from one\u0026rsquo;s real life. But now at this point in time, it\u0026rsquo;s important that my work (especially development related work) has something to be attributed to, hence why I\u0026rsquo;m breaking that seperation just a tad bit. Less art? Aww man # On some sadder news, I can\u0026rsquo;t make as much art as I used to in the past. Mostly because I\u0026rsquo;ve exhausted all of my ideas and new ones come at a slow rate, and partly because I simply don\u0026rsquo;t have much time anymore, which is why starting next year, I want to make at least 2 major pieces; one in May-June (Spring/Summer), and one in November-December (New Year\u0026rsquo;s, like the now). There will likely be some other stuff in between, but those are when I plan to make \u0026ldquo;major pieces\u0026rdquo;, pieces that wil make it on to my ArtStation. Ideally it wouldn\u0026rsquo;t have gotten to this point, but that\u0026rsquo;s just what\u0026rsquo;s it\u0026rsquo;s going to be moving forward.\nI\u0026rsquo;m also doing a personal rebrand of myself as an artist (in conjunction with the previous section), so I\u0026rsquo;ve made a new logo and watermark (SVGs below): New Logo New Watermark\nThis Year\u0026rsquo;s New Year\u0026rsquo;s Render # (that title is a bit of a mouthful)\nWith all of that out of the way, if you\u0026rsquo;re just here for the render, here it is, you\u0026rsquo;re welcome\nOne of the fun things about making these every year is trying to outdo last year\u0026rsquo;s version of me, so here\u0026rsquo;s a breakdown of some of the new things I did for this particular piece.\nVivy # One of the things I\u0026rsquo;ve been working on is Vivy: an in-house fork of MCprep with a much improved materials system. I\u0026rsquo;ve been rambling a bit about it on Mastodon the past couple of months.\nNow I know some people may be saying \u0026ldquo;gib download pls\u0026rdquo;, especially after seeing the PBR demo demo.\nWhile I initially wanted to make Vivy a full fork of MCprep (interestingly enough I actually got an offer from Kevin at Pidgeon Tools, the developers of Super Image Denoiser, to make it a part of their line of addons but denied the offer), I\u0026rsquo;ve since decided to keep it as an in-house fork, for these reasons:\nAs impressive as the demos look, there\u0026rsquo;s a lot of manual work involved I\u0026rsquo;ve been trying to design a simple to use UI for the full material system, but it\u0026rsquo;s basically impossible I don\u0026rsquo;t want to deal with angry 12 year olds expecting something as easy as MCprep (Vivy is very much designed for people with a lot of Blender experience) I have made it availible on GitHub for transparency reasons, but keep the above in mind if you plan on trying to use it yourself: StandingPadAnimations/Vivy MCprep with 100% more control! Python 0 0 Optimizing Scenes for Laptops # When I began working on this back in November, I made one rule: until the final render, everything is to be done on a laptop (the final render would be rendered on a system with an RTX 4060 and 32 GB of RAM). The reason is simple: using my more powerful system for everything is an absolute pain, from dealing with Windows (my daily driver is an Arch Linux system) to dealing with a Fornite gamer that doesn\u0026rsquo;t seem to understand time management, it\u0026rsquo;s easier for me to make everything on my laptop, then do the final render on a more powerful system.\nTraditionally we think of optimization in Blender as optimizing the render time, but in this case, I had to optimize for something else: viewport performance. After all, you can\u0026rsquo;t have a render if Blender keeps crashing. In the past, this wasn\u0026rsquo;t something I normally had to think about, but on a laptop, it\u0026rsquo;s a number 1 priority.\nThe main thing that caused crashing of my laptop was all objects being in the scene at once. For a while, I tried to just deal with it, but it got so bad that I began to sit down and rework how I do collections.\nIn the past, I would just have a mess of an outliner. but now I actually needed to have something organized to manage the mess. I did this by having a seperate forground and background collection, and seperating everything into those 2 collections. This allowed me to easily hide the background (unneeded 90% of the time) and unhide it when it came time to render. Note: There\u0026rsquo;s some additional stuff I added after taking this screenshot, but I think you get the point. Plus, the additional stuff are inuendos ;D. Happy searching!\nIt was with this trick that allowed me to continue working on a simple laptop. For further optimization, I even split the OBJ in 2 to allow seperate background and forground pieces. I also \u0026ldquo;duplicated\u0026rdquo; the OBJ to use in the background, but using collection instances. What I did was, in a seperate file, create a version of the OBJ with some heavy decimation (finer details aren\u0026rsquo;t needed for things far away), then imported it as an instance. This meant that, while I had multiple \u0026ldquo;duplicates\u0026rdquo; of this background OBJ, they all shared the same object data, which was important to reducing memory usage. Sadly they\u0026rsquo;re not really noticeable at the final camera angle, but it\u0026rsquo;s a neat trick nontheless.\nMicro-detailing # For this scene (and all scenes moving forward), I\u0026rsquo;m trying a new method called micro-detailing, where I add smaller details on models, but try to keep the scene as a whole distinctly Minecrafty.\nIt\u0026rsquo;s quite obvious on the dress and purse, but I also used higher resolution textures (32x32 instead of 16x16) with PBR. In addition, I added surface imperfections to this particular render, such as scratches on metal, smudges on glass, grunge on the window, etc: I began experimenting with stuff like this (minus surface imperfections) a while back in some earlier pieces, like with stockings:\nAnd denim:\nThere\u0026rsquo;s several reasons I did this, but the main one being that\u0026rsquo;s unique. Yes, there are already artists who do \u0026ldquo;realistic Minecraft rendering\u0026rdquo;, but I have yet to see one that did it within the bounds of Minecraft itself.\nPart of it (indirectly) is also to make it harder for AI to replicate. I think David Revoy puts it best on his blog post \u0026ldquo;My Brushstrokes against AI-art\u0026rdquo;\nDo you want to know the irony of all this? These developments towards a stronger personal style in my art, though I am pained to admit it, come from the pressure of the existence of AI-generated images.\nWhile indirect, I did find that with the rise of AI in art, I started using more and more complex tricks in my rendering. Is it coincidence? Probably, but it\u0026rsquo;s still interesting nonetheless.\nRigging # When I started putting together the scene back in late November, an issue I encountered a lot was Blender crashing. While now I know this was due to bad organization, at the time I only had the Blender logs to work with, and I concluded it was the rig\u0026rsquo;s circular dependencies causing the problem.\n\u0026ldquo;Circular dependencies?\u0026rdquo;\nIn rigging, armatures often depend on drivers or constraints, and these drivers/constraints can depend on bones. This creates a \u0026ldquo;dependency chain\u0026rdquo;. However, a circular dependency chain can occur if a bone depends on something that, at some point, depends on the bone itself. Normally this isn\u0026rsquo;t too bad, but should be fixed since it can cause crashes. At the time, I was using BPS V3, specifically from Ocean Monument, made all the way back in Blender 2.8. The rig has some annoying circular dependencies, so I decided to try and make my own rig.\nNow eventually I decided to try and fix BPS V3, but\u0026hellip;.\n3 words: Zophiekat Black Magic (Zophiekat was the one who made BPS V3)\nEventually I get my rig finished (in fact, the post with Kaiyona in stockings used the new rig), but by then I figured out the actual cause for crashes, so this is the last piece that\u0026rsquo;ll be using BPS V3.\nGoodbye BPS V3, you were a pain in the ass on the final stretch. I\u0026rsquo;ll be making a seperate post on the new rig later.\nHow Things Could Have Been Different # Work on this particular render began all the way back in October, with skin making and purse modeling, with the actual scene building in late November. In between, I was working on my laptop to PC workflow and traveling to Pakistan to visit family. I made a first render on December 3rd, and the final render you see here was rendered on December 23rd. In comparison, last year\u0026rsquo;s render for New Year\u0026rsquo;s was made throughout the span of a week. As such, this scene changed massively as I continued to work on it for a month. Initially, I wanted to make this an outdoor scene, so I worked a lot on outdoor lighting:\nHowever, I wasn\u0026rsquo;t a huge fan of it, so I modelled a basic interior with some pink lighting:\nI think I have to explain my thought process here. I had an idea that never came to fruition of Blobby registering Kaiyona for a Tinder and getting a match (stupid I know) By the way Blobby is this blob. He\u0026rsquo;s not a common character I use anymore, maybe I should bring him back: As I was thinking out the idea a bit further, I figured a good match in this hypothetical scenario would be the implied cameraman stuck in Blender: So while technically not an actual characther (yet\u0026hellip;), I did imagine this would be taking place at a date with Keith.\nNow see, camera nerds tend to have a lot of lights, crazy ones at that, so I\u0026rsquo;d imagine the pink light wouldn\u0026rsquo;t be out of place (especially with all of the other ights). Eventually I added some extra lights to get something close to what we have:\nAnd that\u0026rsquo;s basically the final major change. Now that I think about it, I could have made the background more intersting, but I think it\u0026rsquo;s best to save those for future pieces.\nHappy New Year\u0026rsquo;s # I think I\u0026rsquo;ll stop here since this post is getting near 2000 words. I wish y\u0026rsquo;all a happy new year\u0026rsquo;s, and cya next year!\n","date":"24 December 2023","externalUrl":null,"permalink":"/posts/2023/12/new-years/","section":"Posts","summary":"","title":"Happy Holidays!","type":"posts"},{"content":"Hey y\u0026rsquo;all, it\u0026rsquo;s been a while since I\u0026rsquo;ve written on the blog, so here\u0026rsquo;s some updates.\nWebsite Updates # I\u0026rsquo;ve now updated the website to use a proper domain. In the past, the domain for the website was at 30 characters (standingpadanimations.github.io), which wasn\u0026rsquo;t memorable, so I\u0026rsquo;ve purchased a domain for the website and now it\u0026rsquo;s simply https://standingpad.org. That should hopefully make it easier to remember this place.\nBlender # I\u0026rsquo;ve began work on a piece for new years (basically a tradition at this point). Why this early? Well\u0026hellip;\nMastodon Post Caption: I'm going to start working on a render for new years (2 months to make this exceptionally good), but the catch is I'm going to be using this laptop and keyboard setup for it all until I have to render Wish me luck Yeah, I\u0026rsquo;m doing this all on a laptop, so I need the extra time. That being said, I\u0026rsquo;ve gotten a good amount of stuff done so far. In fact, I\u0026rsquo;ve changed the background of this website to be one of the viewport WIPs! Mastodon Post Caption: After playing around with the lighting, I think I'm getting somewhere. #wip #blender #blender3d Well that\u0026rsquo;s really it for this post, see y\u0026rsquo;all later!\n","date":"12 November 2023","externalUrl":null,"permalink":"/posts/2023/11/some-progress/","section":"Posts","summary":"","title":"Some Progress","type":"posts"},{"content":"After a lot of conversion and pain, all PNG images have been converted to WebPNGs. This means now the images on this website are smaller and load almost immediately :D!\nEnjoy!\n","date":"8 October 2023","externalUrl":null,"permalink":"/posts/2023/10/website-update/","section":"Posts","summary":"","title":"Website Update! Images now load Faster!","type":"posts"},{"content":"MCprep 3.5 is now released! I won\u0026rsquo;t go too much in depth on the changes (TheDuckCow can do that better then I can), but it was a long development cycle. We made it to the end though.\nOf course a lot of you are probably here because of the splash art that was choosen for MCprep 3.5. This is baed off of an earlier work I did last year: There are however some changes, mostly because the blend file for the splash is distributed to MCprep users:\nRemoval of cyborg tail (not really noticable in the original, but it\u0026rsquo;s a hallmark of my work) Desaturation of character (your eyes are not tricking you, my OC in the splash is desaturated!) This actually wasn\u0026rsquo;t the only idea for the splash. In total, I sent 5 works (that worked well with a 16:9 aspect ratio) and we choose from there. To quote TheDuckCow on why this particular piece was chosen:\nOf course, if I didn\u0026rsquo;t have the 16:9 constraint (or really the constraint on landscape), I probably would have chosen this image (mostly because a lot more MCprep features were used here): But I digress.\nBefore I end this post, I do want to say that I will be taking a break from MCprep, but I have a post with more details on that.\nTaking a Break 27 September 2023\u0026middot;217 words IRL That about wraps it up, Cya!\n","date":"30 September 2023","externalUrl":null,"permalink":"/posts/2023/09/mcprep-3.5-release/","section":"Posts","summary":"","title":"MCprep 3.5 Release!","type":"posts"},{"content":"As stated on the MCprep repo, I will be taking a break from MCprep for the next development cycle. This also includes the MCprep community server (beyond what is required for me to do my job as a mod).\nI think however I should elaborate on the reasoning a bit more.\nIn the past, I\u0026rsquo;ve noticed that I get pretty\u0026hellip; what\u0026rsquo;s the best word for this?\nYeah let\u0026rsquo;s go with that. Needless to say, it\u0026rsquo;s not a good thing when dealing with MCprep users, and really has caused me more issues.\nThere\u0026rsquo;s another layer to this though: around fall and winter my emotional state tends to get a bit more\u0026hellip; what\u0026rsquo;s the right word?\nBefore y\u0026rsquo;all get concerned, it\u0026rsquo;s nothing to be concerned about, but arounnd winter my emotional state doesn\u0026rsquo;t tend to fare well. It wasn\u0026rsquo;t as bad last year, but I have a feeling it\u0026rsquo;s going to be pretty bad this year (cause I\u0026rsquo;m old now :D). I don\u0026rsquo;t want that to make my issue of being too critical on people even worse.\nFor now I\u0026rsquo;ve decided on the entirity of the next MCprep development cycle, but who knows how the future will turn out? Perhaps I might skip another if it gets to it.\nI think that\u0026rsquo;s really all for me to say, cya!\n","date":"27 September 2023","externalUrl":null,"permalink":"/posts/2023/09/taking-a-break/","section":"Posts","summary":"","title":"Taking a Break","type":"posts"},{"content":"My birthday was 8 days ago, but sadly I couldn\u0026rsquo;t do some rendering on that day, so here\u0026rsquo;s a late birthday piece to me: Enjoy!\n","date":"11 September 2023","externalUrl":null,"permalink":"/posts/2023/09/birthday-render/","section":"Posts","summary":"","title":"Happy Birthday to Me","type":"posts"},{"content":"","date":"26 August 2023","externalUrl":null,"permalink":"/tags/programming/","section":"Tags","summary":"","title":"Programming","type":"tags"},{"content":"EDIT 09/09/2023: I was made aware of how the script could be improved on GitHub, so I\u0026rsquo;ve edit this post to add those suggestions.\nEDIT 27/02/2024: I\u0026rsquo;ve updated the content to clean up some things and, and overall improve the quality\nIt all started with me changing browsers.\nRecently I switched from Librewolf to Vivaldi. While I like Vivaldi, I didn\u0026rsquo;t like how there was no Flatpak version (since Flatpaks are sandboxed). However, I figured this would make a good opportunity to learn sandboxing. Little did I know that this was going to be a headache.\nSimple Sandboxing # For this project, I decided to use Bubblewrap, as that\u0026rsquo;s the underlying program Flatpak uses to sandbox, and after a bit of digging and looking at examples for Chromium browsers, I created the following:\n#! /usr/bin/bash bwrap \\ --symlink /usr/lib /lib \\ --symlink /usr/lib64 /lib64 \\ --symlink /usr/bin /bin \\ --symlink /usr/bin /sbin \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/bin /usr/bin \\ --ro-bind /etc /etc \\ --ro-bind /usr/share /usr/share \\ --ro-bind /opt/vivaldi /opt/vivaldi \\ --dev /dev \\ --dev-bind /dev/dri /dev/dri \\ --proc /proc \\ --ro-bind /sys/dev/char /sys/dev/char \\ --ro-bind /sys/devices /sys/devices \\ --ro-bind /run/dbus /run/dbus \\ --dir \u0026quot;$XDG_RUNTIME_DIR\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/wayland-1\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/wayland-1\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/pipewire-0\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/pipewire-0\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/pulse\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/pulse\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/bus\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/bus\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/app/org.keepassxc.KeePassXC\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/app/org.keepassxc.KeePassXC\u0026quot; \\ --dir /tmp \\ --ro-dir \u0026quot;$HOME\u0026quot; \u0026quot;$HOME\u0026quot; \\ --dir \u0026quot;$HOME\u0026quot;/.cache \\ --bind \u0026quot;$HOME\u0026quot;/.config/vivaldi \u0026quot;$HOME\u0026quot;/.config/vivaldi \\ --bind \u0026quot;$HOME\u0026quot;/VivaldiDownloads \u0026quot;$HOME\u0026quot;/Downloads \\ --ro-bind \u0026quot;$HOME\u0026quot;/.icons \u0026quot;$HOME\u0026quot;/.icons \\ --setenv XCURSOR_PATH \u0026quot;/run/host/user-share/icons:/run/host/share/icons:$HOME/.icons\u0026quot; \\ /usr/bin/vivaldi-stable --enable-features=UseOzonePlatform --ozone-platform=wayland Great, this is good, right? No. Sure, it\u0026rsquo;s better then nothing, but still behind Flatpak, because Portals.\nWhat\u0026rsquo;s the Deal with Portals? # In the shell script above, we expose the entire a couple of directories, including the home directory. Sure, it\u0026rsquo;s read-only, but nothing will stop a website from just reading those files and sending them somewhere else. We need to make a smaller hole.\nA simple way of doing this would be to give access to a single folder, and then copy files when needed. This works, but is cumbersome to the user (me). It would be nice if we could automatically do that. Well that\u0026rsquo;s what the FileChooser Portal does. It allows the user to select any file, but not require the program to have access to the home directory at all, through some dbus proxy magic.\nImplementing Portals # So we just set up portals, right? After some digging around, I made some tweaks and created this:\n#! /usr/bin/bash APP_FOLDER=\u0026quot;$XDG_RUNTIME_DIR/app/net.vivaldi.Vivaldi\u0026quot; mkdir -p \u0026quot;$APP_FOLDER\u0026quot; if [ -z \u0026quot;$DBUS_SESSION_BUS_ADDRESS\u0026quot; ]; then export DBUS_SESSION_BUS_ADDRESS=\u0026quot;unix:path=$XDG_RUNTIME_DIR/bus\u0026quot; fi bwrap --bind / / --die-with-parent --clear-env \\ xdg-dbus-proxy \\ \u0026quot;$DBUS_SESSION_BUS_ADDRESS\u0026quot; \\ \u0026quot;$APP_FOLDER/bus\u0026quot; \\ --filter \\ --log \\ --talk=org.freedesktop.* \\ --call=\u0026quot;org.freedesktop.portal.Desktop=org.freedesktop.portal.Settings.Read@/org/freedesktop/portal/desktop\u0026quot; \\ --broadcast=\u0026quot;org.freedesktop.portal.Desktop=org.freedesktop.portal.Settings.SettingChanged@/org/freedesktop/portal/desktop\u0026quot; \u0026amp; sleep 0.1 bwrap \\ --unshare-all \\ --share-net \\ --symlink /usr/lib /lib \\ --symlink /usr/lib64 /lib64 \\ --symlink /usr/bin /bin \\ --symlink /usr/bin /sbin \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/bin /usr/bin \\ --ro-bind /etc /etc \\ --ro-bind /usr/share /usr/share \\ --ro-bind /opt/vivaldi /opt/vivaldi \\ --dev /dev \\ --dev-bind /dev/dri /dev/dri \\ --proc /proc \\ --ro-bind /sys/dev/char /sys/dev/char \\ --ro-bind /sys/devices /sys/devices \\ --ro-bind /run/dbus /run/dbus \\ --dir \u0026quot;$XDG_RUNTIME_DIR\u0026quot; \\ --chmod 0700 \u0026quot;$XDG_RUNTIME_DIR\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/wayland-1\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/wayland-1\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/pipewire-0\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/pipewire-0\u0026quot; \\ --ro-bind \u0026quot;$XDG_RUNTIME_DIR/pulse\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/pulse\u0026quot; \\ --ro-bind \u0026quot;$APP_FOLDER/bus\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/bus\u0026quot; \\ --bind-try \u0026quot;$XDG_RUNTIME_DIR/app/org.keepassxc.KeePassXC\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/app/org.keepassxc.KeePassXC\u0026quot; \\ --dir /tmp \\ --ro-bind \u0026quot;$HOME\u0026quot; \u0026quot;$XDG_RUNTIME_DIR/dconf\u0026quot; \\ --bind \u0026quot;$HOME\u0026quot;/.config/vivaldi \u0026quot;$HOME\u0026quot;/.config/vivaldi \\ --bind \u0026quot;$HOME\u0026quot;/VivaldiDownloads \u0026quot;$HOME\u0026quot;/Downloads \\ --ro-bind \u0026quot;$HOME\u0026quot;/.icons \u0026quot;$HOME\u0026quot;/.icons \\ --setenv XCURSOR_PATH \u0026quot;/run/host/user-share/icons:/run/host/share/icons:$HOME/.icons\u0026quot; \\ --new-session \\ --die-with-parent \\ /usr/bin/vivaldi-stable --enable-features=UseOzonePlatform --ozone-platform=wayland \u0026quot;${@}\u0026quot; We launch xdg-dbus-proxy, tell the sandbox to use that as its bus, and then launch the program. We\u0026rsquo;re all good, right? No, because of xdg-desktop-portal\u0026rsquo;s behavior. xdg-desktop-portal (which I\u0026rsquo;ll shorten to xdp) is the one that actually provides the portals. However, it acts differently when a Flatpak is using a portal vs a sandboxed (but non-Flatpak) program. Why? Because xdp expects non-Flatpaks to have access to the system anyway.\nsigh, really?\nThis behavior is not well documented, and really doesn\u0026rsquo;t make sense at all. Supposedly it has something to do with security, but I digress. I opened a GitHub issue on the xdp repo and was told the following:\nYou do not use a sandbox that is supported by xdp (flatapk or snap) and therefore xdp assumes your program is allowed to access this path because it assumes it is an \u0026ldquo;normal\u0026rdquo;, unsandboxed host program.\nVery unfortunate situation right now that xdp has only support for these two and nor for a generic one (via some kind of plugin or api mechanism). So if you use firejail/bubblejail/plain bubblewrap/crablock you can not benefit from the documents portal (and other portals have a \u0026ldquo;is allowed anyway\u0026rdquo; logic too).\nThere\u0026rsquo;s a hacky workaround by pretending to be a platpak. You can place a minimal /.flatpak-info inside your sandbox. See netblue30/firejail#4716 (comment).\n- rusty-snake\nSo I did that:\n--ro-bind-data 3 \u0026quot;/.flatpak-info\u0026quot; \\ ... /usr/bin/vivaldi-stable --enable-features=UseOzonePlatform --ozone-platform=wayland \u0026quot;${@}\u0026quot; \\ 3\u0026lt;\u0026lt;EOF [Application] name=$APP_NAME EOF But\u0026hellip; it didn\u0026rsquo;t work.\nAfter many days of debugging and looking into /proc/{PID}/root (yes, that\u0026rsquo;s how annoying debugging sandboxes is), it turns out xdg-dbus-proxy also needed to have a .flatpak-info file in the root directory for its sandbox. This is apparently to be expected.\nIf you\u0026rsquo;re using xdg-dbus-proxy, then the message bus is receiving a D-Bus connection from xdg-dbus-proxy, not directly from the sandboxed app itself. This means that when xdg-desktop-portal asks the message bus \u0026ldquo;who sent this message?\u0026rdquo;, the message bus tells it the process ID of xdg-dbus-proxy.\nFlatpak puts /.flatpak-info in the filesystem root of both xdg-dbus-proxy and the actual sandboxed app, so that the xdg-dbus-proxy can be identified as being run on behalf of the sandboxed app. If you are faking a Flatpak app then you will need to do the same.\n- Simon McVittie\nThis was pretty simple to add:\nbwrap \\ ... --bind \u0026quot;$XDG_RUNTIME_DIR\u0026quot; \u0026quot;$XDG_RUNTIME_DIR\u0026quot; \\ --ro-bind-data 3 \u0026quot;/.flatpak-info\u0026quot; \\ ... --broadcast=\u0026quot;org.freedesktop.portal.Desktop=org.freedesktop.portal.Settings.SettingChanged@/org/freedesktop/portal/desktop\u0026quot; 3\u0026lt;\u0026lt;EOF [Application] name=$APP_NAME EOF Restricting Portal Access # Currently our script has access to every portal though, which is not ideal. We need to restrict portal access to what we actually need. This is pretty easy though, and we just need to switch from a wildcard for --talk\n--talk=org.freedesktop.* To specifying each portal we want:\n--talk=\u0026quot;org.freedesktop.portal.Flatpak\u0026quot; \\ --talk=\u0026quot;org.freedesktop.portal.Documents\u0026quot; \\ --talk=\u0026quot;org.freedesktop.portal.Desktop\u0026quot; \\ --talk=\u0026quot;org.freedesktop.portal.Notifications\u0026quot; \\ --talk=\u0026quot;org.freedesktop.portal.FileChooser\u0026quot; \\ Of these, -talk=\u0026quot;org.freedesktop.portal.Flatpak\u0026quot; is a must, as we have to emulate what Flatpak does.\nOf course, this is only a fraction of all the portals available, so check the Portal API reference for determining what your application needs.\nZombie Processes # After a lot of time, I\u0026rsquo;ve noticed that the method here results in zombie processes after closing the browser. This is due to the browser being a child process of the script, but as we also run an instance of xdg-dbus-proxy, the script doesn\u0026rsquo;t exit at all.\nFortunately this is pretty easy to solve, we simply add this line to the beginning of the script:\ntrap 'trap - SIGTERM \u0026amp;\u0026amp; kill -- -$$' SIGINT SIGTERM EXIT I\u0026rsquo;ve uploaded the completed script on GitHub, and that\u0026rsquo;s pretty much all there is (but I\u0026rsquo;ll be updating this as new information comes). Cya!\n","date":"26 August 2023","externalUrl":null,"permalink":"/posts/2023/08/sandboxing-time/","section":"Posts","summary":"","title":"Sandboxing Native Programs with Bubblewrap","type":"posts"},{"content":"","date":"26 August 2023","externalUrl":null,"permalink":"/tags/tech/","section":"Tags","summary":"","title":"Tech","type":"tags"},{"content":"Today I\u0026rsquo;ve now added comments to my website! You can try them out on the bottom of this post.\n\u0026ldquo;Wait I need GitHub for comments \u0026gt;:C\u0026rdquo;\nOk slight caveat, GitHub is needed for comments. The comments section takes advantage of GitHub Discussions (in fact, the discussion for this page is here), so a GitHub account is needed. Hey, less spam.\nSince it\u0026rsquo;s based off of GitHub Discussions, you can use the entire GitHub Markdown Spec, so there\u0026rsquo;s a lot of options for formatting comments. Oh, and you can add reactions to this post as well. Enjoy!\n","date":"12 August 2023","externalUrl":null,"permalink":"/posts/2023/08/comments/","section":"Posts","summary":"","title":"Comments have now been added!","type":"posts"},{"content":"I know I said I would post one final render on Instagram (and here) later last week, but some things came up, so here y\u0026rsquo;all go (also welcome if this is your first time on my website):\nNormally I\u0026rsquo;d go into the specifics on how I made it, but as I mentioned in the last post (see below), I don\u0026rsquo;t have access to my files (long story, see below), so I can\u0026rsquo;t take any screenshots to show what I\u0026rsquo;ve done.\nSome Updates 19 July 2023\u0026middot;941 words IRL Nonetheless, I\u0026rsquo;ll try to explain through writing. For this render, I tried 2 new techniques:\nLight linking (a Blender 4.0 feature) Black and white balancing Light linking is a new Cycles feature in Blender 4.0 that allows isolating the objects a light can influence. This is big for character lighting, as it allows for more options to light and seperate characters from backgrounds better, without impacting the rest of the scene. It\u0026rsquo;s a feature that\u0026rsquo;s been around in other 3D programs for at least a decade now, and has only just gotten implemented in Blender.\nBlack and white balancing meanwhile is exactly what it sounds like, balancing black and white. This is done by adding a color chart to the scene, sample the black and white parts of the chart (i.e. pick black and white on the color chart using the color picker), and setting the black and white levels to those values. With black and white balancing, I was able to make the render overall feel less \u0026ldquo;stabby\u0026rdquo; and easier to color grade.\nThat\u0026rsquo;s really all I have, cya!\n","date":"27 July 2023","externalUrl":null,"permalink":"/posts/2023/07/cya-instagram-render/","section":"Posts","summary":"","title":"Cya Instagram","type":"posts"},{"content":"","date":"27 July 2023","externalUrl":null,"permalink":"/tags/rendering/","section":"Tags","summary":"","title":"Rendering","type":"tags"},{"content":" Hey there, if you\u0026rsquo;re from Instagram and never been on my website, then welcome (I\u0026rsquo;ve had this for almost a year now). There\u0026rsquo;s some updates I got to talk about.\nFirst off I\u0026rsquo;ll be deleting my Instagram account in a couple days. There\u0026rsquo;s a couple of reasons for it, but it mostly boils down to Meta now requiring an account to view posts. When it comes to posting content online, I go by the following philosophy \u0026ldquo;use the lowest barrier possible\u0026rdquo;, and there\u0026rsquo;s a reason for that. I don\u0026rsquo;t want to be the reason someone makes an account for a service they weren\u0026rsquo;t going to use anyway. Since Meta is now requiring accounts to view posts, I don\u0026rsquo;t want to post on Instagram anymore. I don\u0026rsquo;t post much there anyway (we\u0026rsquo;ll get to that in a second), nor do I trust Meta anyways (I literally run Instagram in a seperate browser on a completely seperate computer). I\u0026rsquo;ll be posting my renders here now, which has the added bonus that I can talk a lot more about the process (and no image compression either!).\nI mentioned how I don\u0026rsquo;t post much online anymore, and like everything there\u0026rsquo;s a reason for that. It\u0026rsquo;s extremely difficult for me to do 3D art nowadays.\nThe first thing to understand is that the system I use to render (which has all of my files) is a shared system, shared between me and some other family members. The person that uses it the most (who I\u0026rsquo;ll call \\(dx\\) cause they\u0026rsquo;re as painful to deal with as calculus) is a gamer, and over the past year or so they\u0026rsquo;ve been replacing the components of the system (not the actual PC itself, just stuff like the mouse and keyboard). As a result, they feel like they own the system completely now, and use it for hours at a time. As such, for me to render, I have to wait months for a time when \\(dx\\) won\u0026rsquo;t be on it for even a little bit of time.\nNow here\u0026rsquo;s the problem: \\(dx\\) really does not want me to be rendering anymore (it\u0026rsquo;s been the case for a year and a half now). Why I have no idea, but frankly that\u0026rsquo;s just how it is. I am older (much older in fact), but they\u0026rsquo;re twice my size, and will always use the \u0026ldquo;I\u0026rsquo;ve bought most of the parts\u0026rdquo; argument (even though again, the actual PC itself is shared, they have no ownership over it). This meant that for the past year and a half, I\u0026rsquo;ve had no access to the system I use for rendering, including 3+ years worth of files and assets (about 40+ GB), which makes rendering on my laptop much harder. In the past I\u0026rsquo;ve tried to transfer those files, but to no avail (at least in a way that wouldn\u0026rsquo;t piss off \\(dx\\)). They don\u0026rsquo;t want to negotiate, they don\u0026rsquo;t want to split time, they just want to do what gamers do all day.\n\u0026ldquo;But Standing, didn\u0026rsquo;t you say every couple of months you get an oppertunity?\u0026rdquo;\nYes, but only for a few hours, which causes the following problems:\nWorse art. Too much sitting (did I mention \\(dx\\) is one of those \u0026ldquo;if you\u0026rsquo;re off the chair you\u0026rsquo;re not using it\u0026rdquo; gamers?), which is not good health wise (especially cause I already sit a lot daily). Sleep deprevation; it doesn\u0026rsquo;t help that the only times \\(dx\\) is not gaming is at 10 PM, and often I end up working till midnight on a render. I\u0026rsquo;ve already felt the worse effects of sleep deprevation with my memory (for any kids reading this, please sleep well, you don\u0026rsquo;t want to end up like me and forget decades of your life). At this point, I think I\u0026rsquo;m going to have to throw in the towel, at least until I solve the files and assets problem. I\u0026rsquo;m too tired to be dealing with \\(dx\\)\u0026rsquo;s shenanigans. If that means less Blender content, so be it. I got better things to do then waste time dealing with \\(dx\\), which leads me to explain what\u0026rsquo;s going to happen here.\nI\u0026rsquo;ll still be posting here, there\u0026rsquo;s no doubt about it. I got a couple of things planned, including some new posts on Cycles optimization (I started a series of posts here on it last December, but haven\u0026rsquo;t touched it since) and some expansion on the lighting guide to add some stuff I missed, especially light linking (now that Blender 4.0 has it). I\u0026rsquo;m also working with TheDuckCow on some MCprep development changes (but I\u0026rsquo;ll save those for him to announce), and I\u0026rsquo;ve been working on some projects (but again I\u0026rsquo;ll save those for later). That means there\u0026rsquo;s going to be a lot less Blender content here. I\u0026rsquo;ll be posting last render here hopefully by the end of this week, but I\u0026rsquo;ve left a preview in the article thumbnail.\nIf you want to get notifications for new posts, then there\u0026rsquo;s 2 ways. The first and most preferable way is RSS (yes I\u0026rsquo;m old school), and the second way is following me on Mastodon (all of my socials are avalible on the main page where all of the icons are, as well as my email), but I\u0026rsquo;d only advise following me on Mastodon if you want to actually use Mastodon (again I don\u0026rsquo;t want to be the reason people make accounts for services they otherwise don\u0026rsquo;t want to use). RSS has the advantage of only requiring an RSS reader, of which there are many.\nI know a these updates are a lot to take in, but I hope they were easy to read. Until next time, cya!\n","date":"19 July 2023","externalUrl":null,"permalink":"/posts/2023/07/some-updates/","section":"Posts","summary":"","title":"Some Updates","type":"posts"},{"content":"\u0026ldquo;Hey why are all of the images reloading now?\u0026rdquo;\nSo this past day I\u0026rsquo;ve updated all of the URLs on this website to use the scheme /posts/year/month/article over /posts/article. In addition, I\u0026rsquo;ve also moved all of the images from /static/imgs to /post/year/month/article/gallary. All in all, this means the browser\u0026rsquo;s cached version of this website is no longer valid and now everything has to be reloaded.\nI apologize for any inconvinience this may cause.\n","date":"27 June 2023","externalUrl":null,"permalink":"/posts/2023/06/fyi-you-might-have-cache-issues/","section":"Posts","summary":"","title":"FYI You Might Have Some Cache Issues","type":"posts"},{"content":"This just happened about an hour ago as I write this. So I\u0026rsquo;m just chilling when I get a GitHub notification email. Normally these aren\u0026rsquo;t a bug deal, but this one was a bug deal:\nTheDuckCow ran compile.sh (which is how we build MCprep) and it ended up deleting his installed Blender addons\u0026hellip; across 7 versions of Blender.\nShit.\nInitially it was thought to be a issue on dev, but it turned out to be an issue on milestone-3-5-0. I remembered this commit I made earlier this year, specifically the following section:\nSC2115 is defined here on the ShellCheck wiki. It occurs when a bash script tries to perform a deletion on a variable that might be null. This can have massive consequences, such as with this user who lost their home directory due to Valve (of all companies) making this mistake for the Steam client.\nThe mistake I made was in the \u0026ldquo;fix\u0026rdquo;:\nrm -rf \u0026quot;${i/$NAME:?}/\u0026quot; Which Bash interprets as:\nReplace i with its value Check if NAME is null and if so, error out. Otherwise replace it with its value Remove anything in i that matches with NAME (which is nothing) Remove the resulting path When I wrote this, I thought Bash was going to expand i and NAME after checking if they\u0026rsquo;re null, and then put them with / in between (it\u0026rsquo;s a filepath). However, Bash instead took it as a whole expression. The correct line should have been:\nrm -rf \u0026quot;${i:?}/${NAME:?}\u0026quot; Which translates to:\nCheck if i and NAME are null and error out if they are Replace i and NAME with their values Remove the resulting path What that means was instead of removing path/to/addons/folder/MCprep, it was removing path/to/addons/folder, which meant all of TheDuckCow\u0026rsquo;s installed Blender addons were deleted.\nIn my defense, ShellCheck should have given a warning in this case (I\u0026rsquo;ve checked again today, ShellCheck considers everything fine), and I\u0026rsquo;ve opened an issue on the ShellCheck repo for this very case, but past me should have known.\nThankfully we\u0026rsquo;re replacing compile.sh with a state of the art build system written in PEP8-complient Python, so hopefully this won\u0026rsquo;t happen again (I hope). Just in case though, I\u0026rsquo;ve fixed the error on the MCprep repo, but that isn\u0026rsquo;t going to restore any files.\nMoral of the story: when working with Bash, no errors still means there\u0026rsquo;s errors.\n","date":"25 June 2023","externalUrl":null,"permalink":"/posts/2023/06/i-broke-production/","section":"Posts","summary":"","title":"How a Syntax Error I Made Deleted TheDuckCow's Files","type":"posts"},{"content":"EDIT 6/22/2023: I\u0026rsquo;ve changed the caustics to use Diffuse Ray \u0026amp; Camera Ray instead of Shadow Ray and edited the post accordingly. If screenshots don\u0026rsquo;t look like they match, that\u0026rsquo;s why.\nSo in yesterday\u0026rsquo;s post I mentioned how a long time ago I attempted to make a water shader based off of RTX Minecraft.\nShip Render 21 June 2023\u0026middot;630 words Blender How I Did It Well, I\u0026rsquo;ve been playing around on my laptop and I think I\u0026rsquo;ve gotten closer. I present to you, RTX Water Shader V2: Electric Booga- slap\nBut before I release it, we got to talk about how we got here.\nLooking at Screenshots for a little too long # Yesterday when talking about my first attempt, I showed some screenshots of how water looks in RTX Minecraft.\nLet\u0026rsquo;s disect this into 2 parts: surface and underwater rays\nSurface # Let\u0026rsquo;s take another look at the first screenshot:\nWe see a couple of things:\nThe water is transparent when close to the camera, but reflective when farther away The reflections aren\u0026rsquo;t sharp by any means, but they\u0026rsquo;re strong The water isn\u0026rsquo;t pure blue, it\u0026rsquo;s a slight blueish-green (though that might be due to the biome) So lets start with the water color:\nThese 6 nodes will act as the basis for everything else. Now we need to emulate that \u0026ldquo;transparent up close, reflective far\u0026rdquo; effect\u0026quot;.\nFresnel # Don\u0026rsquo;t freak out when seeing \\(\\theta\\), it\u0026rsquo;s just the Greek letter Theta and in this context, it refers to the angle formed by a ray of light and the normal (a line perpendicular to the surface) of the surface it strikes at. Fresnel occurs due to light hitting a surface at different angles. The following diagram from Scratch a Pixel helps to illustrate:\nIn light physics, when a ray hits a surface, it bounces back at the same angle that it was at before. For example, if \\(\\theta_i\\) is the angle of the incoming ray, and \\(\\theta_r\\) is the angle of the reflected ray, then $$ \\theta_i = \\theta_r $$\nAlright this is fancy, but how does this tie in with water? We\u0026rsquo;ll, it\u0026rsquo;s a matter of perspective. From far away, the rays that that hit and are reflected are very steep, so it appears as glossy. Close up meanwhile, the angle isn\u0026rsquo;t as steep, so it appears as transparent.\nI still need to fix the reflection and refraction of this water shader, but we\u0026rsquo;ve disected a lot so far. Now let\u0026rsquo;s move on.\nUnderwater Rays # Let\u0026rsquo;s look at the other screenshots: A big part of RTX water are the underwater rays. They inherit the color of the surface water, and they\u0026rsquo;re also extremely powerful.\nNormally we would use refraction to create these rays, but:\nCycles sucks at brute force refraction These rays are very Minecrafty So we need to fake the effect. Thankfully, that\u0026rsquo;s easy.\nNote: The following is the reason why this water shader is Cycles only. The first step is to use volumetrics. The reason we have rays appear in the first place is because they\u0026rsquo;re being scattered around by particles before eventually being completely absorbed by said particles. Without volumetrics, no rays will appear. We can do this by creating a cube, scale it so it\u0026rsquo;s entirely underwater, and then set the material to Principled Volume BSDF with the Color set to pure white:\nNext we must create a texture that will allow us to let light pass through some areas (but not all). Since we want something Minecrafty, we can use a white noise texture (scaled down extremely) and clamp it to be purely black and white. To allow us to animate the texture, we set it to 4D and animate the W value. We can then apply our texture to the result, and then use that as the color for a Transparent BSDF node:\nTo make this only affect shadows, we would normally use the Is Shadow Ray output of the Light path node, but I\u0026rsquo;ve combined a Is Diffuse Ray and Is Camera Ray to reduce how strong the light passing through is. In this case, we check to see if a diffuse ray is at max 0.1 before then letting it through. Afterwards, we use camera ray to make the surface not a weird combination of the mask and water surface.\nAnd that\u0026rsquo;s really all there is to the water shader. I\u0026rsquo;ve went ahead and added it to my resources page if you\u0026rsquo;re interested in downloading this, and I\u0026rsquo;ll cya later!\n","date":"22 June 2023","externalUrl":null,"permalink":"/posts/2023/06/rtx-water-shader-2/","section":"Posts","summary":"","title":"Making a Minecraft RTX Style Water Shader in Blender: Attempt 2","type":"posts"},{"content":"","date":"21 June 2023","externalUrl":null,"permalink":"/tags/how-i-did-it/","section":"Tags","summary":"","title":"How I Did It","type":"tags"},{"content":"It\u0026rsquo;s been a while since I\u0026rsquo;ve render, so I made this cause why not.\nThere\u0026rsquo;s some interesting things in it though, so let\u0026rsquo;s get to those.\nClouds and Aurora # For the clouds and aurora, I decided to use Complementary Reimagined as my reference. What I like about Reimagined is that it sticks with the Minecraft style while enhancing it. So I opened a Minecraft world and took some screenshots:\nFor the clouds, I just appended the MCprep cloud model from the sky files (looks like I need to add a \u0026ldquo;just clouds\u0026rdquo; option) and added a slight bevel. Then I replaced the material with a Principled Volume BSDF node.\nI don\u0026rsquo;t think I did proper justice to the original Reimagined clouds though. Looking closer at the Reimagined clouds, it seems to actually be a translucent mesh, but without checking the actual shader code, I can\u0026rsquo;t confirm anything. Anyway it was time for me to move on to the aurora, and this was te hard bit. I had to somehow create a cube of tall cubes, and I figured I could do it with geometry nodes (why do I now sound like the Blender version of NileRed?).\nSo, I created a curve object, and played around with some nodes, eventually getting this result:\nBasically in the geometry nodes, I was turning the curve into a mesh, and then adding a point for every vertice. Then at each point, I added a very tall and skinny cube. Finally, I took all of the cubes, and shifted them up slightly. It wasn\u0026rsquo;t perfect, but that\u0026rsquo;s fine for this render.\nFor the material, I just use gradient texture, manipulated it, and added some color, before putting that all into a Principled Volume BSDF node, and was left with the following result:\nNow with those in place, I could move on to actually rendering.\nWater # Just like the clouds and aurora, I wanted to have a water shader that merely acted as an enhancement of the existing Minecraft water. However unlike the previous section, I already had an existing water shader that I could use. This time though, instead of basing it off of Reimagined, I based it off of RTX Minecraft. While I prefer Java edition shaders over RTX Minecraft in most cases, I really liked how the water looked in RTX (Screenshots from Nvidia):\nOf course my recreation is very crude and really doesn\u0026rsquo;t look nearly as good, but I think it looks pretty nice. Of course the scene being night doesn\u0026rsquo;t really do proper justice, so I\u0026rsquo;ve changed the sun position for these screenshots:\nWith some work, I might be able to get it closer to the RTX style, but for now I\u0026rsquo;m happy with how it looks. If you\u0026rsquo;re interested in using it, I\u0026rsquo;ve made it freely availible on my resources page.\n\u0026ldquo;So wait, what does the water shader look like?\u0026rdquo; \u0026ldquo;Doesn\u0026rsquo;t look that ba- oh now I see\u0026rdquo; I also took the time to edit it for ice, but I don\u0026rsquo;t think it looks that good: Minecraft ice is a pretty difficult thing to make look good (beyond using MCprep\u0026rsquo;s default material generation), and that\u0026rsquo;s made harder with all of the water. Anyhow I just ignored it, and I think it looks fine from a distance.\nWhile this render is of course nowhere near as good as some of the other ones I\u0026rsquo;ve made, I think it was a good test for Reimagined style auroras/clouds and RTX style water, and now I know where to move on with making look better (oh and a good refresher since I haven\u0026rsquo;t used Blender in a while). For now though, I\u0026rsquo;m a bit done with node stuff, and I think I know what I want to do next.\nUntil then, cya!\n","date":"21 June 2023","externalUrl":null,"permalink":"/posts/2023/06/ship-render/","section":"Posts","summary":"","title":"Ship Render","type":"posts"},{"content":"\u0026ldquo;Hey what the hell happened here?\u0026rdquo;\nI\u0026rsquo;ve updated the website for the first time in a while. I was browsing through hugo themes and saw this really nice one: nunocoracao/blowfish Personal Website \u0026amp; Blog Theme for Hugo HTML 1311 378 So after some painful migration, we\u0026rsquo;ve now gotten this new website. I\u0026rsquo;ve also went ahead and updated the older posts to take advantage of the new theme.\nHope y\u0026rsquo;all enjoy!\nIn addition to the new website layout, I\u0026rsquo;ve also migrated my lighting guide over here as well. Sadly that means no more PDF version, but the web version looks 10 times better. I\u0026rsquo;ve embedded the articles below, but you can also find them here (just click the \u0026ldquo;Lighting Guide\u0026rdquo; button) Lighting Guide Introduction and Why We light 370 words Introduction and why do we light scenes in the first place? A Practical Example 945 words Let\u0026rsquo;s go over how we can light a scene starting from scratch What About a Different Way? 215 words Let\u0026rsquo;s go over another way we can light this scene, this time using shadow Let's Demolish Stuff! 511 words Let\u0026rsquo;s take some existing scenes and deconstruct the lighting Conclusion 98 words Concluding remarks ","date":"16 June 2023","externalUrl":null,"permalink":"/posts/2023/06/website-update/","section":"Posts","summary":"Website has a new look now!","title":"Website Update!","type":"posts"},{"content":" +Note: MCprep is turning 10 on October 28\nIn February 2023, the Mine-imator (also known as Mi) developer Nimi announced the end of Mi\u0026rsquo;s development:\nOf course, this has triggered an exodus of Mi users to Blender. While that\u0026rsquo;s a good thing, it forces us MCprep developers to have to rethink MCprep\u0026rsquo;s design goals. See, just like many Blender addons, MCprep aims to not abstract too much. However, many Mi users are used to and expect heavy abstraction, which conflicts with the design goals of MCprep.\nIn addition, we\u0026rsquo;re now at a point where man-power. As I have stated before (in the article below), for 10,000 users, we only have 2 active maintainers and 4 external contributers (1 active at the moment). This brings up the larger issue that MCprep development isn\u0026rsquo;t sustainable.\nAt this point a question has to be asked: will MCprep make it to 12 years? 15? As it stands, with the current circumstances and lack of manpower, I wouldn\u0026rsquo;t be surprised if it didn\u0026rsquo;t even make it to 11.\nSustainability of MCprep # Most users want new features. Personally, I would love to make an MCprep release solely focused on fixing bugs and actually revamping ancient parts of the MCprep codebase, but I bet you a big portion of the community will be mad that we (god forbid) choose to focus on making MCprep\u0026rsquo;s existing features better and not add anything new. Even now, we\u0026rsquo;ve already got people asking when we\u0026rsquo;re going to add 1.20 assets, despite 1.20 coming out 5 days ago (as I write this).\nAnd that\u0026rsquo;s not factoring life outside of MCprep. TheDuckCow and I are getting busier each day, and it\u0026rsquo;s only going to ramp up. TheDuckCow works at Poligon and is working the game Wheel Steal (you should check it out, it\u0026rsquo;s looking really good now). Meanwhile I\u0026rsquo;m just starting to enter the architectual rendering and IT worlds.\nSo where do we go?\nUltimately the community decides. MCprep is open source, which means contributing code is easy. While TheDuckCow and I might be too busy with our day-to-day lives to do active MCprep development, we do have time to look at submissions and pull requests. But those submissions pull requests must come from the community. If the community is not willing to volunteer at least a little bit of their time in submitting contributions, then MCprep\u0026rsquo;s fate has already been sealed.\nI\u0026rsquo;ve already been talking with TheDuckCow on a \u0026ldquo;Summer of MCprep\u0026rdquo; sort of idea (based of Blender\u0026rsquo;s Summer of Code) where we create a list of goals and specifically focus on certain aspects of MCprep. A part of me though feels it\u0026rsquo;s going to be useless, but we have to try.\nHappy almost-10 years to MCprep, let\u0026rsquo;s hope it makes it to 11.\n","date":"13 June 2023","externalUrl":null,"permalink":"/posts/2023/06/mcprep-isnt-sustaintable/","section":"Posts","summary":"","title":"MCprep Development Isn't Sustainable","type":"posts"},{"content":" Update # I have closed the Prepping API proposal with the following:\nHowever, I feel that the article is still important for addon developers, so I\u0026rsquo;ve kept it here\nOriginal Article # Just yesterday I gave the greenlight for Prepping API, a proposal that would allow users to create their own prep material functions in Python.\nBut is it worth it?\nThat proposal was made in 2022, and for about a year now I\u0026rsquo;ve spent time thinking about how such an API could be secured. The problem is obvious: this API would allow arbitrary Python scripts to be loaded.\nSandboxing? Not in Blender where we have only pure Python. Restricting modules? I guess we\u0026rsquo;ll ban half of the standard library. Custom scripting language? Not with the current state of things.\nDoes it matter?\nI think it does. As I stated in my comment:\nThis new feature is a both a blessing and a curse. It\u0026rsquo;s a blessing since it allows MCprep to better support edge case setups, and gives users more power in material generation, but I feel that I\u0026rsquo;ve just approved of something I\u0026rsquo;ll regret in the future.\nMCprep\u0026rsquo;s audience is mostly 12 year olds who want to have fun making Minecraft animations. There\u0026rsquo;s nothing fun in losing your system. This question really applies to the entire Minecraft animation space, I\u0026rsquo;ve started seeing a surge of rigs that require custom, poorly maintained (most of the time) addons made by random people. I fear one of these days, we\u0026rsquo;re going to have a widespread issue of users losing their systems due to a malicious script, or a poorly defended exec statement.\nSo let me rephrase the question: Does it matter when the majority of Minecraft animators are 12 year olds looking for fun?\nYes. That\u0026rsquo;s all I need to say.\n","date":"18 May 2023","externalUrl":null,"permalink":"/posts/2023/05/prepping-api-cleared-now-what/","section":"Posts","summary":"","title":"Prepping Api Cleared! Now What?","type":"posts"},{"content":"After years of supporting Blender 2.7x in MCprep, we\u0026rsquo;ve now decided to remove support starting with MCprep 3.5.\nHardcore Blender 2.7x user walks in\n\u0026ldquo;WHAT THE F-CK DID YOU SAY!?!?!? Reverse it, NOW!\u0026rdquo;\nYeah no, we\u0026rsquo;re not doing it. It\u0026rsquo;s too much work to suppor-\n\u0026ldquo;Sounds like something a lazy developer would say\u0026rdquo;\nShut up, this is for the better, let me explain.\nThe Massive Pain That is, 2.7x Support # When we say \u0026ldquo;2.7x support\u0026rdquo;, it includes a variety of things:\nUsing supported syntax Wrapping API methods Tricking Python itself (I\u0026rsquo;ll get back to this) Guard statements for versioning Testing (MCprep 3.4.2 was tested with 15 different versions of Blender) It\u0026rsquo;s not as simple as \u0026ldquo;snap your fingers and boom, support\u0026rdquo;, it\u0026rsquo;s a much larger ordeal. Here\u0026rsquo;s an example of some code we use for compatability:\ndef ui_scale(): \u0026quot;\u0026quot;\u0026quot;Returns scale of UI, for width drawing. Compatible down to blender 2.72\u0026quot;\u0026quot;\u0026quot; prefs = get_preferences() if not hasattr(prefs, \u0026quot;view\u0026quot;): return 1 elif hasattr(prefs.view, \u0026quot;ui_scale\u0026quot;) and hasattr(prefs.view, \u0026quot;pixel_size\u0026quot;): return prefs.view.ui_scale * prefs.system.pixel_size elif hasattr(prefs.system, \u0026quot;dpi\u0026quot;): return prefs.system.dpi / 72 else: return 1 \u0026ldquo;I don\u0026rsquo;t understand what this does\u0026rdquo;\nThis is just to return the scale of the UI. And that\u0026rsquo;s just the tip of the iceberg. Remember when I said we had to trick Python itself for 2.7x support? Yeah\u0026hellip;\ndef make_annotations(cls): \u0026quot;\u0026quot;\u0026quot;Add annotation attribute to class fields to avoid Blender 2.8 warnings\u0026quot;\u0026quot;\u0026quot; if not hasattr(bpy.app, \u0026quot;version\u0026quot;) or bpy.app.version \u0026lt; (2, 80): return cls if bpy.app.version \u0026lt; (2, 93, 0): bl_props = { k: v for k, v in cls.__dict__.items() if isinstance(v, tuple)} else: bl_props = { k: v for k, v in cls.__dict__.items() if isinstance(v, bpy.props._PropertyDeferred)} if bl_props: if '__annotations__' not in cls.__dict__: setattr(cls, '__annotations__', {}) annotations = cls.__dict__['__annotations__'] for k, v in bl_props.items(): annotations[k] = v delattr(cls, k) return cls \u0026ldquo;But that says to avoid 2.8 warnings!\u0026rdquo;\n2.8 warnings caused by 2.7x syntax. And notice the if bpy.app.version \u0026lt; (2, 93, 0)? That\u0026rsquo;s where this function starts to cause headaches for many, many people.\nSee this function performs something that we\u0026rsquo;re not supposed to be doing, but we do anyway. Well that caused headaches in 2.93 when Blender (understandably) changed the internal type used for properties. Since that function runs before MCprep actually registers the panels with Blender (in other words, make Blender aware of the panel\u0026rsquo;s existence), this meant that for a while in 2.93, MCprep would outright not work.\nBut the issue extends beyond MCprep and into the addon updater, an updater that is used by many, many other Blender addons. Like MCprep, the addon updater also has the same function for backwards compatability, and when 2.93 hit, it too was affected. That means hundreds, if not thousands of Blender users were affected by this change, as well as developers, all because a small group of users are stubborn to upgrade to modern versions of Blender, but expect support for the addons they have.\nHow small? Here\u0026rsquo;s data from the last 90 days about showing the amount of users who have MCprep 3.4-3.4.2 installed: 2% total, yikes. Sure it\u0026rsquo;s still 354 installs, but compared to the 10,500+ downloads of MCprep, it\u0026rsquo;s not worth supporting 2.7x still.\n2.7x user goes through the ground\nHuh, I guess they got bored, but yeah this change is pretty massive.\nWhat Does This Mean? # The MCprep 3.4 series will be the last to support 2.7x. That means 2.7x users have 3 options:\nMigrate to modern versions of Blender Stick with the MCprep 3.4 series Fork MCprep and make it compatible with 2.7x (I do not suggest this route but there\u0026rsquo;s crazy people in the world) I think the first option is the simples-\n\u0026ldquo;But migrating is so hard\u0026rdquo;\nIt may seem that way, but I\u0026rsquo;ve talked with a buddy who used 2.7x quite a bit after 2.8\u0026rsquo;s release, and this is what he had to say:\nSince the release of 2.8, Blender has made massive leaps in features. Some of them include:\nAI denoising Collections EEVEE Cycles X (making Cycles way, way faster) OptiX rendering for RTX GPUs HIP rendering for AMD GPUs and Apple Silicon oneAPI for Intel GPUs GPU subdivision Geometry nodes Light groups Better subsurface scattering Faster and less noisy volumetrics in Cycles Real time compositing in the viewport (tecnically still in development, but I\u0026rsquo;ve tried it and it\u0026rsquo;s awesome) Better refractive caustics with MNEE (also known as shadow caustics) Faster OBJ importing (which MCprep utilizes in Blender 3.5, hint hint) Asset browser And much, much more\u0026hellip; There\u0026rsquo;s also been some recent developments in things like light linking (finally!), spectral rendering, GPU denoising with OIDN, and many other things that I\u0026rsquo;m not aware of. In my opinion, keeping 2.7x support in MCprep for this long was a mistake, because we didn\u0026rsquo;t have an incentive for users to upgrade and benefit from the massive improvements. I hope that by dropping 2.7x compatability, we help users realize how much better modern Blender is, and how dumb it is to not use something just because the GUI looks different. Dropping 2.7x support is for the better, for both MCprep, and the userbase.\n","date":"17 March 2023","externalUrl":null,"permalink":"/posts/2023/03/dropping-27x-support-in-mcprep/","section":"Posts","summary":"","title":"Why Dropping 2.7x Support in MCprep is for the Better","type":"posts"},{"content":"As the MCprep 3.4.2 release date draws nearer, I think it\u0026rsquo;s important to remind users how MCprep development works, and how important it is that MCprep receives supports from the community. I feel like people have forgotten how much work goes into MCprep, and I think a little reminder wouldn\u0026rsquo;t hurt.\nOverview # Currently, MCprep only has 2 active maintainers (TheDuckCow and myself). While the MCprep GitHub repo says there\u0026rsquo;s 7, most of them haven\u0026rsquo;t contributed in a while: Now obviously TheDuckCow would have the most commits (411 at the time of writing this) since he\u0026rsquo;s been working on MCprep for almost 10 years now (yes, MCprep has been around for 10 years), with myself being behind with 96 commits. The rest have made a couple of commits here and there, and as far as I know that was before we had an official guide on contributing. So we\u0026rsquo;re already spread thin when it comes to implementing new features and bug fixes (not factoring how we also have things to do IRL).\nLike any open source project though, MCprep depends on outside contributions, and we have a couple. These are the users who have contributed in the past:\nzNightlord: Blender 3.4 Mix node compatability Tiefseetauchner: Camera setup for panoramas Ghost (Ok Ghost is just a placeholder GitHub uses for deleted accounts) + Bytzo: The modern texture generator we\u0026rsquo;re all familier with I can literally count on one hand how many users have contributed to MCprep. In contrast, if we check the amount of unique IDs recorded by Google Analytics from MCprep 3.3.0 to 3.4.1 (for 2022), we find that 10,740 unique IDs have been recorded in the last year alone. If we add MCprep 3.2.5 and 3.2.5.1 to the mix, that number increases to 10,867.\nNow counting unique IDs isn\u0026rsquo;t completely accurate, but it does give a general glimpse in the amount of MCprep users. If we add in that MCprep supports Blender versions 2.78-3.4 (that is 15 versions) of Blender), it\u0026rsquo;s impressive that MCprep receives quite stable updates every 4-6 months.\nI\u0026rsquo;m not giving these stats to make people feel bad, I\u0026rsquo;m giving these stats to outline the reality of MCprep development. People seem to complain about MCprep features, while doing nothing to fix such issues. That isn\u0026rsquo;t to say complaining about MCprep is a bad thing, but people seem to forget how spreadly thin we already are.\nHow the Community Can Help # The simplest way the community can help is improve the assets MCprep provides, as that\u0026rsquo;s were most complaints seem to arise from. We already have asset submissions open for those interested. While most people submit rigs for new mobs, it\u0026rsquo;s important to know that we also accept improved/replacement rigs for any existing mobs in MCprep (especially as BSS seems to no longer update their rig pack).\nAlso, report bugs on GitHub, but please don\u0026rsquo;t treat it like a support channel. That\u0026rsquo;s what the MCprep Discord server is for.\nIf you know how to code in Python and have some experience, then bug fixes are also welcome. We have a guide on contributing code. We do expect however a basic understanding of the Blender Python API (BPY) and Git. A good first contribution is PEP8 Formatting (basically reformatting MCprep\u0026rsquo;s code to make it comply with PEP8 convention), since that\u0026rsquo;s doesn\u0026rsquo;t rely too much on BPY and is relatively easy (just reformatting code).\n","date":"11 March 2023","externalUrl":null,"permalink":"/posts/2023/03/problems-of-mcprep-development/","section":"Posts","summary":"","title":"Problems of MCprep Development","type":"posts"},{"content":"UPDATE: As of March 11th, 2023, most of these are now confirmed for the 3.4.2 release\nAs some of you know, I\u0026rsquo;m an MCprep developer, and as part of what I do I work on adding features and fixing bugs in MCprep. Not that, I also help review pull requests and fix bugs.\nThe latest version of MCprep, MCprep v3.4.1 was released in August of last year. While it may seem like MCprep development is dying, that couldn\u0026rsquo;t be further from the truth.\nHere\u0026rsquo;s some of the features that are in the works right now.\nPrep Materials without Emissive Nodes # This may seem like something useless, but this feature was originally planned as a Cycles Optimizer improvement in 3.4.2 (before I left MCprep development for a bit of time) but has since been moved to the core of prep materials.\nThis means for users that don\u0026rsquo;t need emissive nodes (like EEVEE users), they get a much easier node setup to work with (especially when using SEUS or Specular). Here\u0026rsquo;s a comparison: Wow, so much better.\nBut why was this feature originally going to be a Cycles optimizer feature? It\u0026rsquo;s because in Cycles, mesh lights (like what MCprep generates) causes a lot more noise then normal lamps; by removing mesh lights we can reduce the amount of noise, which is a form of optimization.\nIt was decided in the middle of development however that it would be better to do it directly in prep materials rather then in the Cycles Optimizer, hence the move.\nCurrently it\u0026rsquo;s a WIP, and you can follow its development on Github\n3.4 Mix Node Support # Blender 3.4 changed from MixRGB to a new general Mix node. While it does convert MixRGB nodes already, we can\u0026rsquo;t rely on this. As such, zNightLord made a pull request near the end of last year that implements support for the new Mix node, which was merged in January of this year.\nCool, just one slight issue: an indexing problem that prevented prep materials from working in certain conditions. Originally thought to occur in edge cases, it was found in MCprep Kaion that the issue extended further into texture swap and what not.\nThis doesn\u0026rsquo;t impact any release version of MCprep but regardless it needed to be fixed. A new pull request fixes this issue, and should be merged in the next couple of days.\nEven with the bug it\u0026rsquo;s still an exciting feature for Blender compatibility, and who knows what we could do with the new Mix node.\nUsing the New C++ OBJ Importer # Be prepared for massive performance improvements when importing OBJs in Blender 3.5 and above in the next version of MCprep, there\u0026rsquo;s work being done on using the new C++ OBJ importer shipped with Blender 3.1 and above.\nBut wait, why will this change only apply to Blender 3.5 and above? Well, until Blender 3.5, the C++ OBJ importer was missing certain features that MCprep used when importing OBJs, specifically importing split groups. It was debated on if the C++ OBJ importer should also be used between 3.1 and 3.4, but ultimately we settled on 3.5 and above only for feature parity. We don\u0026rsquo;t want to deal with angry users afterall.\nYou can follow development on Github\nProper ACES Support # The same pull request that adds the use of the C++ importer also adds proper ACES support for importing OBJs.\n\u0026ldquo;But wait, didn\u0026rsquo;t MCprep add ACES support a while back?\u0026rdquo;\nFor prep materials it did, but not for OBJs. This has been a bug reported as far back as 2020, and was thought an issue with Blender itself.\nWhile that is true, it goes back to the MTL file generated by Minecraft world exporters. On another Github repo, it was mentioned that certain parts of the MTL could be commented out to prevent errors when importing, so we tested that, and indeed it fixed the issue.\nSo now MCprep will edit MTL files when importing an OBJ (if anything other then Standard or Filmic is used).\n\u0026ldquo;But wait, that sounds bad\u0026rdquo;\nYeah, that change is still the subject of debate. What will likely happen is that MCprep will back up the MTL somewhere (maybe in a new folder) before editing, or something like that. Either way, it\u0026rsquo;s still an exciting feature, and will fix a 3 year old bug in MCprep.\nChecking Feature Compatability with OBJs # This is a big one, MCprep will now check an OBJ\u0026rsquo;s header (if exported with Mineways) to determine if texture swap and animate textures can be used without issues.\nHere\u0026rsquo;s some screenshots of how this looks. If you notice in the MCprep panel, as long as the right OBJ is selected, texture swap can\u0026rsquo;t be used (because it was exported with incorrect settings). This is a massive improvement as it prevents one of the most common issues we see, although it only apples to Mineways OBJs, due to them exporting a header (although we are looking into a standard header format world exporter developers can use). Still better then nothing.\nYou can follow along here on Github\nHow can I test these new features? # Sadly MCprep doesn\u0026rsquo;t provide pre-release builds, so you have 2 options:\nCompile MCprep from the dev branch Use MCprep Kaion (shameless self promo) The former is a bit complicated for newcomers, so let\u0026rsquo;s look at the latter.\nMCprep Kaion is a fork of MCprep specifically designed to help accelerate MCprep\u0026rsquo;s development. As you might notice, most of these new features actually come from MCprep Kaion. One of Kaion\u0026rsquo;s goals is to provide new features early to users easily. MCprep Kaion has all the features you\u0026rsquo;d expect from MCprep, and much more, but there is a cost.\nMCprep Kaion is not as well tested as MCprep itself, and often times issues will prop up. Many times it\u0026rsquo;ll recieve multiple updates a week or even in a day, so it\u0026rsquo;s not for those expecting something stable. Still, it aims to provide users with a good user experience, and is a good way of previewing new features.\nIt\u0026rsquo;s also good if you want to test and catch bugs with new features, which helps massively.\nConcluding Remarks # While MCprep\u0026rsquo;s development may seem to be going at a slow pace, it\u0026rsquo;s by no means dead. New features are coming, and that\u0026rsquo;s just the beginning.\n","date":"25 February 2023","externalUrl":null,"permalink":"/posts/2023/02/mcprep-progress/","section":"Posts","summary":"","title":"MCprep 3.4.2 Progress","type":"posts"},{"content":"","date":"9 February 2023","externalUrl":null,"permalink":"/tags/discord/","section":"Tags","summary":"","title":"Discord","type":"tags"},{"content":"On Feburary 11th I\u0026rsquo;ll be shutting my Discord bot EndorCore down.\nBackground # A couple of years back, I coded a Discord bot using the Discord.py framework. It was the primary way I learned Python, and it was a blast while it lasted, but all good things some to an end.\nWhy # For starters, EndorCore is no longer maintained. The last commit on the Github repo was in March of 2022. Because of this, EndorCore has slowly started to lose functionality as time passed and Discord changed the API. Today, EndorCore is just a former husk of what it used to be.\nSecurity Concerns # Right now EndorCore is ran on a Debian server, one that needs some serious maintanince. Back when I started it, it was the only Linux machine I had (these days I use Linux as my daily driver), and as such, stupid mistakes were made, such as:\nNot doing proper updates Installing Python modules systemwide instead of in a virtual environment Not isolating the process In addition, after recently going over the code, EndorCore has sections that in theory would be vulnerable to SQL injection, such as the following:\nif user_result == None: cursor = await self.client.db.cursor() sql = f\u0026quot;INSERT INTO Strikes(Guild_ID, User_ID, Strikes_Have) VALUES({ctx.guild.id}, {member.id}, {first_strike})\u0026quot; await ctx.respond(f\u0026quot;Striked {member}\u0026quot;) await cursor.execute(sql) await self.client.db.commit() await cursor.close() The issue lies in lines such as this:\nsql = f\u0026quot;INSERT INTO Strikes(Guild_ID, User_ID, Strikes_Have) VALUES({ctx.guild.id}, {member.id}, {first_strike})\u0026quot; This should have never been a raw Python format string, and yet it is. Back when I was firsting adding SQL to the EndorCore codebase, lines like this were common. While many have been removed, some still remain. In theory Discord\u0026rsquo;s API should prevent wrongful parameters from being passed, but I can\u0026rsquo;t count on that.\nEndorCore also currently runs an alpha build of Pycord 2.0 from around 2021, and still hasn\u0026rsquo;t been updated. Updating the module would require massive code changes that I\u0026rsquo;m not willing to do.\nAll of this should have spelled the end for EndorCore a long time ago, and fr that I\u0026rsquo;m sorry.\nWhat Happens Now # EndorCore\u0026rsquo;s codebase can be found on Github, but I don\u0026rsquo;t plan on writing documentation on how to deploy it. In my opinion, EndorCore\u0026rsquo;s codebase should never be used anymore, so don\u0026rsquo;t expect any support in working with it. If you plan to make a Discord bot to replace EndorCore, do not make the mistake of not maintaining it for a long time. Discord bots require the attention of a toddler.\nIt\u0026rsquo;s was a good run while it lasted, but now EndorCore\u0026rsquo;s days are numbered. You may continue using its commands until Feburary 11, 2022 when it\u0026rsquo;ll be taken down, but I doubt many will work except for the incredibly simple ones.\nUntil then, cya later.\n","date":"9 February 2023","externalUrl":null,"permalink":"/posts/2023/02/endorcore-shutdown/","section":"Posts","summary":"","title":"EndorCore Is Shutting Down","type":"posts"},{"content":"Yes guys, I\u0026rsquo;m back.\nAnyways, I recently had an idea and made this render: Not my best, but lets talk about how I made it.\nTrees of Light # For this, I used Bforartists 3.4, which is based off of Blender 3.5. Immediately I noticed a slowdown in viewport responsiveness. Thinking it was a driver, I went from Nvidia\u0026rsquo;s Studio drivers to their Game Ready drivers, but no difference.\nSidenote: Nvidia has 2 drivers, Studio and Game Ready. The difference is that Game Ready is less stable but recieves updates quicker, whereas Studio is much more stable. In general I recommend Studio since it has better stability, but if you do mostly gaming with newer PC games, Game Ready is an option.\nIt turns out in Sampling \u0026gt; Lights, there\u0026rsquo;s a new feature called Light Tree. It\u0026rsquo;s a new 3.5 feature and from what I can tell is meant to reduce noise with lights. It\u0026rsquo;s amazing for rendering, but an absolute nightmare for the viewport. Until Blender makes it an option one can enable for the viewport and render individually, I recommend disabling it until it\u0026rsquo;s time to render. Hopefully the next BFA update will disable this by default.\nL I G H T S # This was honestly my least favorite part of the render, but I know people are going to comment on it.\nThere\u0026rsquo;s not many light sources in the scene, other then the sky and some street lamps. There\u0026rsquo;s also some lights to seperate the character from the backround, but honestly I dislike how they\u0026rsquo;re noticable in the rest of the environment (Blender, PLEASE add light linking), but what can you do?\nThey\u0026rsquo;re pretty simple point lights with an IES texture and a blackbody node.\n\u0026ldquo;IES textures?\u0026rdquo;\nsigh\n\u0026ldquo;._.\u0026rdquo;\nBasically IES textures are textures that represent light falloff. They\u0026rsquo;re much more accurate then simply using normal Blender lights.\nColor Grading: Stubbing Your Toe on the Corner of a Wall # This is one of the things I hate the most about this. The thing is, there\u0026rsquo;s not much color in the first place, so color grading was going to be difficult.\nI used what I learned from my New Year\u0026rsquo;s render and attempted to do some color grading. The results were better then what the original render, but I still don\u0026rsquo;t like how it turned out. What can you do though ¯\\_(ツ)_/¯?\nSome Updates # Wait wait wait, don\u0026rsquo;t click away, I know this isn\u0026rsquo;t related, but I have some exiciting updates.\nFor starters, I\u0026rsquo;ve been working on some stuff for a project that a group at my school was doing. The TLDR is that they\u0026rsquo;ve been working on a VR game, and one of them asked if I knew Blender. I showed them this website and got on the team. Here\u0026rsquo;s some screenshots of what I\u0026rsquo;ve been working on (no materials because it has to go to Unity): So that\u0026rsquo;s what I\u0026rsquo;ve been doing.\nI\u0026rsquo;m also pleased to announce MCprep Kaion, a fork of MCprep that aims to bring experimental features to users (as well as adding new features with the goal of going upstream eventually). You can find it here\nAnyway, that\u0026rsquo;s all I really have to say, cya.\n","date":"1 February 2023","externalUrl":null,"permalink":"/posts/2023/02/calm-after-storm-render/","section":"Posts","summary":"","title":"How I did It: Calm After the Storm","type":"posts"},{"content":"I just don\u0026rsquo;t know how else to put it, I\u0026rsquo;m leaving the Minecraft animation world. After what David RB has done, I feel that it\u0026rsquo;s not right for me to continue.\nFor anyone that hasn\u0026rsquo;t heard, David RB, the original owner of Black Plasma Studios, has recently been exposed for being abusive and grooming a minor.\nI initially refrained from making a stance, but after reviewing the evidence released by Posidon, I\u0026rsquo;ve decided I can no longer refrain from making a stance.\nWhat David did was absolutely horrific, and may he be cursed till his final breath.\nAfter everything that has happened, I do not feel right continuing Minecraft rendering. Some may object to this, but this has been haunting me for the past 12+ hours, and I think it\u0026rsquo;s for the best. This also means I will stop working on MCprep. I know that leaves 2 pull requests unfinished, but I think the open source community will get them done eventually.\nWill I return eventually? That\u0026rsquo;s up to fate to decide. Will I stop posting on this blog? No, but things will be changing.\nI know it feels disingenuous to not leave y\u0026rsquo;all with a render, but I don\u0026rsquo;t feel like making one, so here\u0026rsquo;s the files of the renders I feel like releasing (note that there\u0026rsquo;s 2 scenes in each file, Scene and Compositing). If you want the file for a specific render, just DM me on Instagram (or email me if you prefer) and I\u0026rsquo;ll try to find and send it to you. You can find those here.\nWell, I guess that\u0026rsquo;s all I have to say about this, farewell Minecraft animation community. Till we meet again.\n","date":"14 January 2023","externalUrl":null,"permalink":"/posts/2023/01/farewell-for-now/","section":"Posts","summary":"","title":"Farewell for Now","type":"posts"},{"content":"","date":"6 January 2023","externalUrl":null,"permalink":"/tags/hot-takes/","section":"Tags","summary":"","title":"Hot Takes","type":"tags"},{"content":"On June 14th, 2020, Black Plasma Studios announced the plan to cancel Songs of War Seasons 2 and 3, an animation series 5 years in the making, with a story uncontested by anything else. Among the reasons cited include lack of revenue, lack of viewership, and burnout.\nOf course, people were understandbly upset, and couldn\u0026rsquo;t accept the inevitable.\nAlmost 3 years later, there are still people who can\u0026rsquo;t accept that Songs of War is dead.\nThe Great Scism of Songs of War # Immediately following the annoucement, groups began forming with the goal to finish what had been left: Songs of War Season 2 and 3. Particurally, 2 main groups came about: Knights of Ardonia and Helios\nImportant Sidenote: I used to be a scene lighter for Helios, but left due to some internal disputes. Perhaps in the future (unless other former/current staff of Helios don't want me to), I'll write about what happened. This is mostly one of my hot takes, so of course you may take this as you will.\nThere were also a handful of people like Megste, who did the entire series with much smaller teams with hard deadlines. In general, a great fracturing had occured.\nIf you were a Songs of War fan during this period, you now had to follow the development of multiple studios, each with their own motivations and goals. As such, these groups would just have drama non-stop. This would end up leaving a bad taste in people\u0026rsquo;s mouths.\nDavid Didn\u0026rsquo;t Want to Continue, so Stop Asking Him # Looking at the comments of the cancelation annoucement, it\u0026rsquo;s impressive how much people didn\u0026rsquo;t pay attention to the actual announcement. Here\u0026rsquo;s some of the most recent comments (as of writing):\n\u0026ldquo;Please The Whole Community Is Begging For Next Song Of War. Now Do It Don\u0026rsquo;t Care About Views Because You Need To Believe In Your Creation In Your Talent. No Matter What Happen But Never Ever Give Up. You Must Return With Banger The Banger We All Want. Don\u0026rsquo;t Loose Hope. She Believed In You When No One Does (Mother). I Know It\u0026rsquo;s Painful It\u0026rsquo;s Hard But You Must Return Or Be The Dead. I Hope This Message Create Something On Your Mind. If I Am A Millionaire I Will Donate 100 Million To That Animation (Song Of War) For Next Part. But Unfortunately I Am 16 Year Kid Who Had Almost No Money, No Love, Broken. Love You And Your Team. I Hope You Read That Message. Peace .Thank You!\u0026rdquo;\n\u0026ldquo;bro i became depressed for 2 weeks bc this vid was released PLS BRING BACK SONGS OF WAR\u0026rdquo;\n\u0026ldquo;But dude the movie got above 50 million people didn\u0026rsquo;t watch episode cuz the all watched ur movie and also most people don\u0026rsquo;t want to spend some time finding right episode\u0026rdquo;\nGuys, chill, I get why you\u0026rsquo;re upset but it\u0026rsquo;s been 3 years. In that time, David has been working on an FPS game called Arcadian Rift and based on his devlogs sounds way happier and less stressed then during Songs of War production+. If David didn\u0026rsquo;t want to continue, then that\u0026rsquo;s his decision and we should respect that. He\u0026rsquo;s human with his own life, not a robot, how hard is that to understand?\n+ While writing this I was told that David canceled Arcadian Rift due to some IRL issues. As of writing, I do not know the full scope of the issue, but needless to say I think it's even more important that we don't keep bothering David over Songs of War\nUpdate: yeah, let's just say David is not welcome in the Minecraft animation and game dev communities anymore. I've kept the original text for transparency reaons.\nLet\u0026rsquo;s Accept the Death of Songs of War, and Let It Rest in Peace # \u0026ldquo;But why were the assets, scene files, and script released if he didn\u0026rsquo;t want us to continue Songs of War?\u0026rdquo;\nBecause Songs of War assets can be used for other original ideas. The assets contain a treasure trove of items and models most people would pay money for someone to make, and he released them for free. The scene files are also something that can be opened and inspected to see how the David R.B (and the many other Songs of War animators) did stuff. Much of their techniques would remain mostly a secret till the end of times if they had never been released.\nWhen I look at how Songs of War assets are being used, I mostly see 2 things:\nContinuation of Songs of War A spin-off of Songs of War And everytime I just think, \u0026ldquo;That\u0026rsquo;s not why the assets and scene files were released.\u0026rdquo; Imagine what awesome and unique ideas we would have if people wearn\u0026rsquo;t so focused on abusing the Songs of War hype and moved on. In a way, Songs of War would live longer if we just started using the assets for stuff that isn\u0026rsquo;t Songs of War.\nI\u0026rsquo;m guilty of this too, but I\u0026rsquo;ve moved on, and frankly I think the rest of us should to. We\u0026rsquo;ve been digging up the grave of Songs of War way too much, we\u0026rsquo;ve abused the hype way too much, and I think it\u0026rsquo;s time we let it rest in peace.\nIf not for accepting Songs of War\u0026rsquo;s death, at least for letting Songs of War live on beyond itself.\n","date":"6 January 2023","externalUrl":null,"permalink":"/posts/2023/01/songs-of-war-is-dead-let-it-rest-in-peace/","section":"Posts","summary":"","title":"Songs of War Has Always Been Dead; Just Let It Rest in Peace For Once","type":"posts"},{"content":"Anyone who\u0026rsquo;s spent a good amount of time in a help channel on a Minecraft animation server can related to this; you go on help and support, and see the following:\nOne person asking how to import Optifine shaders That guy using 2.79 who gets offended when you politely suggest updating to a new version The person who wants to import animation from a youtube video (I swear I\u0026rsquo;m not making this up) 50 people asking why material mode is so slow 10 more people asking how to show textures 1 or 2 people asking how to move bones (seriously guys?) The poor soul who\u0026rsquo;s dedicated to helping these people (F in the chat for them) The \u0026ldquo;cool\u0026rdquo; 12 year old saying bruh every sentence Basically, people treating help and support as Google. How did we get here?\nImportant Clarification # Don\u0026rsquo;t take this as me hating the concept of help channels. I think they\u0026rsquo;re a good idea, when used correctly. My problem is that we\u0026rsquo;re teaching people to use help channels for issue that can easily be fixed with some digging on Google (or issues that are covered in basic tutorials). In addition, we\u0026rsquo;re also teaching these people not to accept help if it doesn\u0026rsquo;t relate to Minecraft animation or even Blender as a whole, which can not be overlooked.\nPerson ≠ Google # It shouldn\u0026rsquo;t be understated how powerful Google is. Unlike humans, Google is always there, and it can understand the most non-sensical thing. Humans can not, but we\u0026rsquo;re teaching people to treat humans as such.\nI\u0026rsquo;ve seen so many cases of people getting annoyed when waiting for someone to help them with their issue (an issue that 3/4ths of the time can easily be resolved with Google), or people throwing fits in channels when a person doesn\u0026rsquo;t (understandably) understand the problem when given something like \u0026ldquo;why is x happening?\u0026rdquo; (remember, half of 3D software is seeing).\nAnd yet, how many times have I seen someone say \u0026ldquo;next time, start with Google\u0026rdquo; or something along those lines? Not even in double digits.\nIt\u0026rsquo;s understandable; in an age where people get offended over really small things, we don\u0026rsquo;t want to offend others. However, at what point does not wanting to offend others cross a line?\nWhen a person is unable to first solve an issue on their own.\nLet\u0026rsquo;s Stop Feeding Bad Habits # \u0026ldquo;Wow Standing, that\u0026rsquo;s mean\u0026rdquo;\nIt has to be said, we need to stop feeding the behavior that causes people to not use their most powerful tools: their brain box and Google.\n\u0026ldquo;How?\u0026rdquo;\nA method so magical, very few people know it, and those that do are afraid to show it.\nLink the solution to the issue at hand from Google and tell them to read it\nor better yet\nSearch the issue on google and link the results page (you know, the page with all the links)\nSeriously, is it that hard? Are we so concerned with offending other people that we can\u0026rsquo;t even tell them to use Google and go from there, and to use help channels if Google is of no use?\nYes, apparently we are; I know it\u0026rsquo;s a hard pill to swallow, but we\u0026rsquo;ve created this mess, and it is our job to clean up this mess.\n","date":"3 January 2023","externalUrl":null,"permalink":"/posts/2023/01/treating-help-channels-like-google/","section":"Posts","summary":"","title":"Hot Take: We're Teaching People to Treat Help Channels like Google","type":"posts"},{"content":"It\u0026rsquo;s now New Year\u0026rsquo;s Eve, so I made a new years render: This is perhaps the most complicated render I have done to date. I started just before Christmas and finished in about 3 to 4 days.\nHologram Shenanigans # One of the things I wanted to do was 3D holograms, because I\u0026rsquo;ve never done that before. I first followed a Blender Guru tutorial, and the final node setup does essentially the following:\nCreate a grid Duplicate and stack a bunch of those grids Get rid of any point on those grids that doesn\u0026rsquo;t touch the model (in this case Ferris the Rust mascot) Add some icospheres to those points Create a bunch of curve objects from those points Merge them at the bottom vertex (represented by a sphere) \u0026ldquo;If it works, all is good, right?\u0026rdquo;\nblank stare\n\u0026ldquo;Right?\u0026rdquo;\nWell it works, but one slight issue,\nCycles does not like dealing with thousands of curve objects\nRendering a 3D hologram (even on its own) using Blender Guru\u0026rsquo;s method was an absolute pain, and I was prepared to just suck it and deal with it. However, after I mentioned how much of a pain it would be to render on the Erindale server, Slinkcreated a far more optimized version of the hologram.\nEssentially, instead of making thousands of curve objects, he made a setup that takes the model, extrudes it downwards, and then merges the verticies into a single point. The result is the same, but with far less render time.\nAnd that\u0026rsquo;s not all. He also changed how the \u0026ldquo;pixels\u0026rdquo; were created, by creating a cube and scattering points in the volume of that cube, instead of using a stack of grids. This meant that using text as a model was actually fesible, hence the \u0026ldquo;It\u0026rsquo;s 2023\u0026rdquo; hologram.\nNow I tried to see if there was a silver lining with Blender Guru\u0026rsquo;s method. Maybe it was somehow more simpler to explain and expand upon, or maybe it could handle certain edge cases. As far as I can tell however, it\u0026rsquo;s simply not that good. Sure if you\u0026rsquo;re learning geometry nodes or want some practice, it\u0026rsquo;s fine, but in terms of actually using it (especially in Cycles), it\u0026rsquo;s pretty horrific to say the least.\nLet\u0026rsquo;s Not Burn People\u0026rsquo;s Eyes Please # Near the end, I found a short that explained how auto exposure works, and I remembered an addon that allowed for auto exposure.\nCool except one issue: it just wouldn\u0026rsquo;t work with AgX\n\u0026ldquo;Why not just use Filmic then?\u0026rdquo;\nWell\u0026hellip;\nAs you can see, Filmic just looks bad compared to AgX, so that would be a no-no.\nI looked into the addon code and found that each look was accosiated to some exposure values (where the develeoper got those values, idk), which added some complexity. In addition, even with my code changes, the addon still refused to work with AgX.\nSo I scoured the depths of Google and found this auto exposure node, which seemed to work, although with some drawbacks.\nHonestly having it as an addon would have been preferable, but sometimes you got to work with what you got.\nFocus Issues? Let\u0026rsquo;s Add Some Effects! # Even while making the scene I felt there were some \u0026ldquo;focus\u0026rdquo; issues. In other words, I felt like the scene was too chaotic to direct the viewer\u0026rsquo;s eye.\nThe last time I had this much detail was back in the October 2020 MCprep contest, but back then there wasn\u0026rsquo;t a focus. This time, there was a focus, so I had to figure out a way to maintain that focus.\nOh\nSo anyway I added a vignette effect. It\u0026rsquo;s not really noticable, but I think it does a good job at keeping focus.\nOptimization # Like previously, I disabled clamping as it creates more issues then it solves, and I removed all mesh lights from the scene. What makes this scene different was the crazy amount of geometry I had to deal with\nWe already talked about the holograms (before Slink did his magic), but there was also a lot of fireworks (which are all particles), so I simply used a decimate modifier on the bits to reduce as much geometry as possible.\nOther then that, not much else is different from my previous scene.\nSmall Tangent on the Background City # When I originally rendered this, there wasn\u0026rsquo;t much of a background. However, the day before, I realized that I could duplicate the OBJ and render with that as the background.\nLet\u0026rsquo;s just say that was a nightmare. I had to go from Bforartists back to stock Blender due to a weird issue I had while rerendering. I think the result was worth it though, and honestly those couple of hours of debugging were worth it.\nAcknowledgments for this year # I would first like to thank the people who made the scifi map I used to render this and many other renders. ElysiumFire (the people who made the map I used for this and many other renders) are extremely talented when it comes to map making. You may know them for Neon District, the map used to showcase Minecraft with RTX. The fact they also made the map free to download is something I\u0026rsquo;ll always be grateful for.\nI have linked their map before on Twitter, but no one reads that so I feel obligated to link it here. The map can be found here.\nI would also like to thank the people on the Erindale.xyz server, they\u0026rsquo;re extremely friendly and talented (as I\u0026rsquo;ve shown in a couple of my other posts), and the community is welcoming even to Minecraft rendering. Words can not describe how grateful I am.\nAnd finally, I would like to thank anyone who has supported me over the past year. I couldn\u0026rsquo;t have done it without you.\nHappy new year everyone!\n","date":"31 December 2022","externalUrl":null,"permalink":"/posts/2022/12/new-years-2023/","section":"Posts","summary":"","title":"How I Did It: 2023 New Year's Render","type":"posts"},{"content":"Hey guys, just a small IRL update, my family got a cat today! His name is Jason and he\u0026rsquo;s 8 months old. Here\u0026rsquo;s some photos:\n","date":"26 December 2022","externalUrl":null,"permalink":"/posts/2022/12/meet-jason-the-cat/","section":"Posts","summary":"","title":"Meet Jason the Cat","type":"posts"},{"content":"Happy holidays everyone! Sorry I couldn\u0026rsquo;t post yesterday (it was my dad\u0026rsquo;s birthday and birthdays + Christmas Eve don\u0026rsquo;t really mix well).\nOf course, I myself don\u0026rsquo;t celebrate Christmas (cultural reasons) so I\u0026rsquo;m just waiting for New Years. I\u0026rsquo;ve been working on a New Years render, so here\u0026rsquo;s a WIP\nIt\u0026rsquo;s also the second week of winter break for me, which means in about a week I\u0026rsquo;ll have to return back to doing IRL stuff. Not sure how I\u0026rsquo;ll continue writing, but I\u0026rsquo;ll figure it out eventually.\nSpeaking of IRL stuff, my Rust crate Resurgence (a virtual machine backend that can easily be embeded in a Rust project) is almost ready for its first alpha. I don\u0026rsquo;t think I\u0026rsquo;ve ever talked about it on my old website (let alone here), not sure why as it\u0026rsquo;s a big part of what I do normally.\nI think for the rest of this week I\u0026rsquo;ll be working on MCprep/Resurgence and some IRL work I have remaining.\nThat\u0026rsquo;s pretty much all I have to write about today, cya!\n","date":"25 December 2022","externalUrl":null,"permalink":"/posts/2022/12/happy-holidays/","section":"Posts","summary":"","title":"Happy Holidays","type":"posts"},{"content":"I recently had the motivation to make the following render\nAs you can see, there\u0026rsquo;s a lot of reflections, some long test, volumetrics, and other stuff. Since I don\u0026rsquo;t do much Minecraft rendering anymore, I think I\u0026rsquo;ll impart some insight into some of the more technial bits.\nGCC\u0026rsquo;s Time to Shine # \u0026ldquo;GCC?\u0026rdquo;\nBasically, I needed to make a lot of text. Now, I could slam my keyboard a couple of times, but as a nerd I felt like it was the perfect oppertunity to use C++ to generate long text.\nSee, in the *NIX world (so MacOS and Linux), we have a compiler called GCC. GCC is infamous for generating horrific errors (I remember times where it would never stop printing). Since these errors are logged in the terminal (which made masking easy) and they were very technical, I decided to take advantage of those errors to make long text.\nI yoinked the following code from StackOverFlow:\n#include \u0026lt;string\u0026gt;\r#include \u0026lt;iostream\u0026gt;\rstruct Z{};\rvoid foo() {\rstd::string s;\rZ z;\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s }\rand I put it through GCC, which printed the following error:\nLong Error, Click to View .\\file.cpp: In function 'void foo()':\r.\\file.cpp:11:15: error: no match for 'operator\u0026lt;\u0026lt;' (operand types are 'std::ostream' {aka 'std::basic_ostream\u0026lt;char\u0026gt;'} and 'Z')\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r~~~~~~~~~~^~~~\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:108:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; (*)(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp;)) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(__ostream_type\u0026amp; (*__pf)(__ostream_type\u0026amp;))\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:108:7: note: no known conversion for argument 1 from 'Z' to 'std::basic_ostream\u0026lt;char\u0026gt;::__ostream_type\u0026amp; (*)(std::basic_ostream\u0026lt;char\u0026gt;::__ostream_type\u0026amp;)' {aka 'std::basic_ostream\u0026lt;char\u0026gt;\u0026amp; (*)(std::basic_ostream\u0026lt;char\u0026gt;\u0026amp;)'}\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:117:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ios_type\u0026amp; (*)(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ios_type\u0026amp;)) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ios_type = std::basic_ios\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(__ios_type\u0026amp; (*__pf)(__ios_type\u0026amp;))\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:117:7: note: no known conversion for argument 1 from 'Z' to 'std::basic_ostream\u0026lt;char\u0026gt;::__ios_type\u0026amp; (*)(std::basic_ostream\u0026lt;char\u0026gt;::__ios_type\u0026amp;)' {aka 'std::basic_ios\u0026lt;char\u0026gt;\u0026amp; (*)(std::basic_ios\u0026lt;char\u0026gt;\u0026amp;)'}\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:127:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(std::ios_base\u0026amp; (*)(std::ios_base\u0026amp;)) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(ios_base\u0026amp; (*__pf) (ios_base\u0026amp;))\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:127:7: note: no known conversion for argument 1 from 'Z' to 'std::ios_base\u0026amp; (*)(std::ios_base\u0026amp;)'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:166:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(long int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(long __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:166:7: note: no known conversion for argument 1 from 'Z' to 'long int'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:170:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(long unsigned int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(unsigned long __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:170:7: note: no known conversion for argument 1 from 'Z' to 'long unsigned int'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:174:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(bool) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(bool __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:174:7: note: no known conversion for argument 1 from 'Z' to 'bool'\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:693,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:91:5: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(short int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;]'\rbasic_ostream\u0026lt;_CharT, _Traits\u0026gt;::\r^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:91:5: note: no known conversion for argument 1 from 'Z' to 'short int'\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:181:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(short unsigned int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(unsigned short __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:181:7: note: no known conversion for argument 1 from 'Z' to 'short unsigned int'\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:693,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:105:5: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;]'\rbasic_ostream\u0026lt;_CharT, _Traits\u0026gt;::\r^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:105:5: note: no known conversion for argument 1 from 'Z' to 'int'\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:192:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(unsigned int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(unsigned int __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:192:7: note: no known conversion for argument 1 from 'Z' to 'unsigned int'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:201:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(long long int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(long long __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:201:7: note: no known conversion for argument 1 from 'Z' to 'long long int'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:205:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(long long unsigned int) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(unsigned long long __n)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:205:7: note: no known conversion for argument 1 from 'Z' to 'long long unsigned int'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:220:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(double) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(double __f)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:220:7: note: no known conversion for argument 1 from 'Z' to 'double'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:224:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(float) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(float __f)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:224:7: note: no known conversion for argument 1 from 'Z' to 'float'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:232:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(long double) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(long double __f)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:232:7: note: no known conversion for argument 1 from 'Z' to 'long double'\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:245:7: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(const void*) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__ostream_type = std::basic_ostream\u0026lt;char\u0026gt;]'\roperator\u0026lt;\u0026lt;(const void* __p)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:245:7: note: no known conversion for argument 1 from 'Z' to 'const void*'\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:693,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:119:5: note: candidate: 'std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__streambuf_type*) [with _CharT = char; _Traits = std::char_traits\u0026lt;char\u0026gt;; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;::__streambuf_type = std::basic_streambuf\u0026lt;char\u0026gt;]'\rbasic_ostream\u0026lt;_CharT, _Traits\u0026gt;::\r^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:119:5: note: no known conversion for argument 1 from 'Z' to 'std::basic_ostream\u0026lt;char\u0026gt;::__streambuf_type*' {aka 'std::basic_streambuf\u0026lt;char\u0026gt;*'}\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/string:52,\rfrom .\\file.cpp:1:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/basic_string.h:6284:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits, class _Alloc\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, const std::__cxx11::basic_string\u0026lt;_CharT, _Traits, _Alloc\u0026gt;\u0026amp;)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __os,\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/basic_string.h:6284:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: 'Z' is not derived from 'const std::__cxx11::basic_string\u0026lt;_CharT, _Traits, _Alloc\u0026gt;'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ios_base.h:46,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ios:42,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:38,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/system_error:217:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, const std::error_code\u0026amp;)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __os, const error_code\u0026amp; __e)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/system_error:217:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'const std::error_code\u0026amp;'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:497:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, _CharT)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __out, _CharT __c)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:497:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: deduced conflicting types for parameter '_CharT' ('char' and 'Z')\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:502:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, char)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __out, char __c)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:502:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'char'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:508:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, char)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, char __c)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:508:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'char'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:514:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, signed char)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, signed char __c)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:514:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'signed char'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:519:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, unsigned char)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, unsigned char __c)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:519:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'unsigned char'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:539:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, const _CharT*)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __out, const _CharT* __s)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:539:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: mismatched types 'const _CharT*' and 'Z'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:693,\rfrom C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:321:5: note: candidate: 'template\u0026lt;class _CharT, class _Traits\u0026gt; std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp;, const char*)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;_CharT, _Traits\u0026gt;\u0026amp; __out, const char* __s)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/bits/ostream.tcc:321:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'const char*'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:556:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, const char*)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, const char* __s)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:556:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'const char*'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:569:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, const signed char*)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, const signed char* __s)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:569:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'const signed char*'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:574:5: note: candidate: 'template\u0026lt;class _Traits\u0026gt; std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; std::operator\u0026lt;\u0026lt;(std::basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp;, const unsigned char*)'\roperator\u0026lt;\u0026lt;(basic_ostream\u0026lt;char, _Traits\u0026gt;\u0026amp; __out, const unsigned char* __s)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:574:5: note: template argument deduction/substitution failed:\r.\\file.cpp:11:18: note: cannot convert 'z' (type 'Z') to type 'const unsigned char*'\rstd::cout \u0026lt;\u0026lt; z; // typo - meant s\r^\rIn file included from C:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/iostream:39,\rfrom .\\file.cpp:2:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:682:5: note: candidate: 'template\u0026lt;class _Ostream, class _Tp\u0026gt; typename std::enable_if\u0026lt;std::__and_\u0026lt;std::__not_\u0026lt;std::is_lvalue_reference\u0026lt;_Tp\u0026gt; \u0026gt;, std::__is_convertible_to_basic_ostream\u0026lt;_Ostream\u0026gt;, std::__is_insertable\u0026lt;typename std::__is_convertible_to_basic_ostream\u0026lt;_Tp\u0026gt;::__ostream_type, const _Tp\u0026amp;, void\u0026gt; \u0026gt;::value, typename std::__is_convertible_to_basic_ostream\u0026lt;_Tp\u0026gt;::__ostream_type\u0026gt;::type std::operator\u0026lt;\u0026lt;(_Ostream\u0026amp;\u0026amp;, const _Tp\u0026amp;)'\roperator\u0026lt;\u0026lt;(_Ostream\u0026amp;\u0026amp; __os, const _Tp\u0026amp; __x)\r^~~~~~~~\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:682:5: note: template argument deduction/substitution failed:\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream: In substitution of 'template\u0026lt;class _Ostream, class _Tp\u0026gt; typename std::enable_if\u0026lt;std::__and_\u0026lt;std::__not_\u0026lt;std::is_lvalue_reference\u0026lt;_Tp\u0026gt; \u0026gt;, std::__is_convertible_to_basic_ostream\u0026lt;_Ostream\u0026gt;, std::__is_insertable\u0026lt;typename std::__is_convertible_to_basic_ostream\u0026lt;_Tp\u0026gt;::__ostream_type, const _Tp\u0026amp;, void\u0026gt; \u0026gt;::value, typename std::__is_convertible_to_basic_ostream\u0026lt;_Tp\u0026gt;::__ostream_type\u0026gt;::type std::operator\u0026lt;\u0026lt;(_Ostream\u0026amp;\u0026amp;, const _Tp\u0026amp;) [with _Ostream = std::basic_ostream\u0026lt;char\u0026gt;\u0026amp;; _Tp = Z]':\r.\\file.cpp:11:18: required from here\rC:/Program Files/mingw-w64/x86_64-8.1.0-posix-seh-rt_v6-rev0/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/ostream:682:5: error: no type named 'type' in 'struct std::enable_if\u0026lt;false, std::basic_ostream\u0026lt;char\u0026gt;\u0026amp;\u0026gt;'\rI then made a mask using a screenshot of it: And use that as part of the hologram in the render.\nOptimizing # There\u0026rsquo;s a lot I have to say about optimizing. First off, here\u0026rsquo;s a screenshots of the viewport with the volumetrics: \u0026ldquo;But wait, where\u0026rsquo;s the cool godrays in the final render?\u0026rdquo;\nI added those in compositing. In general I think it\u0026rsquo;s easier to use the sunbeams node for godrays.\nBut oh boy did volumetrics become a pain in the but to work with. I enabled homogenous in both world and material settings to make rendering faster. Those helped with render times a little, but there was still the issue with fireflies.\nMagic has Costs, even Clamping # In the Minecraft animation world, we\u0026rsquo;re taught to use a clamping value of 1, not fully understanding what clamping does.\nClamping limits how bright a pixel can be. While it does reduce fireflies, it also reduces desirable highlights to nothing, and can make reflections look mundane. In one of my previous renders, clamping caused reflections to appear darker, an issue which I almost assumed to be a Cycles bug.\nHJ Hornbeck in his blog post \u0026ldquo;The Perfect Clamp\u0026rdquo; explains how to achive a good clamp value that gives good highlights with little fireflies, but the process isn\u0026rsquo;t as strightforward as you might think. It requires a whole lot of rendering test renders, measuring RGB values, and refinement to get a good result. In the end, I decided to avoid clamping completely, and use a value of 0 (which diables it).\nAs the developer behind the MCprep Cycles Optimizer, it may worth it to remove clamping entirely from the optimizer, for it can be extremely destructive when not taking into account the scene itself. Like all settings, clamping should be treated as a scene-dependent thing, not something to just throw the same value at.\nMost fireflies in Minecraft scenes are caused by mesh lights anyway, and after making the hologram emit no light and using a lamp to emulate the light from it, most of the fireflies were nowhere to be found.\nAs far as I can tell, clamping seems to be used as a convinient solution way to solve fireflies caused by mesh lights. If only we had a way of automatically generating lamps for emissive blocks, then we wouldn\u0026rsquo;t have this issue anyway (I have been working on a feature to remove mesh lighting from MCprep materials, so that\u0026rsquo;s a start).\nTldr: Clamping is a terrible solution to fix fireflies caused by mesh lights. We\u0026rsquo;re better off removing mesh lights entirely and using lamps. Clamping should be treated the same as Scrambling Distance, an option that requires careful consideration and refinement.\nHere\u0026rsquo;s the settings I used for this particular render (specifically light paths and color management): These settings are for just this scene (and I use a GTX 1660 Super), so don\u0026rsquo;t copy it hoping it will help with render times. Optimization is scene dependent, not uniform.\nSidenote: Color # One might notice the lack of Filmic in exchange for AgX. I\u0026rsquo;ve written about AgX on my old website but the tldr is that AgX is a better version of Filmic with more color nuance. Once you use it, you can\u0026rsquo;t go back to Filmic.\nCompositing # I do 2 rounds of compositing. The first round is denoising with SID, and the second round is where all the magic happens.\nBefore: After: This is also where I added all those fancy godray effects. I used the denoising depth pass to seperate the world and structures, and plugged it into the sun beams node (btw, Blender devs, if you\u0026rsquo;re reading this, please optimize it or let it take advantage of the GPU, it is horrifically annoying to edit), did some color magic, and added back in. The result is a godly looking background.\nTldr # Basically, a lot of work in optimizing, discovering how bad clamping is, compositing magic, all to make a nice looking render.\nIght, that\u0026rsquo;s it, cya.\n","date":"22 December 2022","externalUrl":null,"permalink":"/posts/2022/12/hacking-holograms-render/","section":"Posts","summary":"","title":"How I Did It: Hacking Holograms Render","type":"posts"},{"content":"","date":"21 December 2022","externalUrl":null,"permalink":"/tags/cycles-optimization/","section":"Tags","summary":"","title":"Cycles Optimization","type":"tags"},{"content":"","date":"21 December 2022","externalUrl":null,"permalink":"/series/cycles-optimization/","section":"Series","summary":"","title":"Cycles Optimization","type":"series"},{"content":"After I made my post yesterday regarding samples and light bounces, I was asked by a buddy a pretty interesting question.\nI try to avoid making certain settings seem \u0026ldquo;magical\u0026rdquo; because with all magic, there\u0026rsquo;s a downside. For GPU rendering (sorry CPU renderers, this setting brings no benifit to y\u0026rsquo;all), one of these settings is known as\nAutomatic Scrambling Distance\nWhile this setting does help with render times a lot, it also requires a lot of tweaking to make it render with little artifacts. I think the best way to make configuring this faster is to understand how it works under the hood.\nWhy Scramble Pixels like Eggs? # In a nutshell, scrambling distance represents how randomized each pixel\u0026rsquo;s randomness value is. We talked about samples in my last post, so I suggest reading that first to get an understanding about what samples are.\n\u0026ldquo;Wait what?\u0026rdquo;\nI was confused at first, so I asked on the Erindale.xyz server (basically a lot of Blender nerds). After some back and forth, I got the following response.\n\u0026ldquo;I still don\u0026rsquo;t get it.\u0026rdquo;\nAlright, let me make a diagram. Here\u0026rsquo;s with a scrambling distance of 1.\nHere, each pixel have a randomized value+ and Cycles uses that to further randomize the samples that it spews into the scene (remember, samples are on a per pixel basis)\n+ This should be more randomized, but it's a quick sketch\nNow here\u0026rsquo;s with a scrambling distance of 0. The higher the scrambling distance, the more randomized these values are.\n\u0026ldquo;So if set to 0, there\u0026rsquo;s no randomness with samples?\u0026rdquo;\nNot exactly. Samples must be released randomly to get finer details. Scrambling distance just makes things more random.\n\u0026ldquo;Oh I get it, so automatic scrambling distance just sets this automatically?\u0026rdquo;\nYes.\n\u0026ldquo;But why does this feature help with render times? And what artifacts occur with it?\u0026rdquo;\nThat brings us on to our next topic.\nAll Magic has a Cost # As I mentioned earlier, automatic scrambling distance can introduce some artifts, but can also massively help GPU users with render times.\nBut how does reducing pixel randomness help with render times?\nThis took a while to find. The Blender Docs say the following:\nLower values Reduce randomization between pixels to improve GPU rendering performance, at the cost of possible rendering artifacts if set too low.\nPresumably it has something to do with VRAM, but I can\u0026rsquo;t be exactly sure. My best guess from past experiance is that rendering is faster with more complex geometry, but I can\u0026rsquo;t be exactly sure.\nSo what are some possible artifacts? Well JC has an example. Yikes, why does this happen?\nIt seems to go back to why path tracers try to randomize samples as much as possible: to get finer details about the geometry.\nAs you can see, all magic comes at a cost.\n\u0026ldquo;So why use it?\u0026rdquo;\nBecause if used correctly, render times can be reduced 10 fold. It also tends to result in cleaner images, which when combined with adaptive sampling (I promise I\u0026rsquo;ll make a detailed explanation on that sometime) can reduce render times. After all, the main reason we put up with long render times is to reduce the amount of noise in our scene.\n\u0026ldquo;So, should I use it?\u0026rdquo;\nIf you use CPU rendering, no, it brings more issues for little benifit. If you use GPU rendering, then it depends on the scene. Personally, I just test it for each scene I do, then try to adjust the scrambling multiplier setting (which goes hand in hand to Automatic Scrambling Distance) before deciding if the artifacts are worth it. I don\u0026rsquo;t use it most of the time (it really hates alpha transparency which I deal with a lot), but when I do it does work well.\nThat being said, it depends on the scene. There\u0026rsquo;s never a specific number I can give that will automatically reduce render times (that\u0026rsquo;s kinda the point behind making these posts).\nI think that\u0026rsquo;s all I really need to explain about Automatic Scrambling Distance. I\u0026rsquo;ll see y\u0026rsquo;all in the next post.\n","date":"21 December 2022","externalUrl":null,"permalink":"/posts/2022/12/cycles-optimization-automatic-scrambling-distance/","section":"Posts","summary":"","title":"Optimizing Render Times in Blender: Automatic Scambling Distance","type":"posts"},{"content":"","date":"21 December 2022","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":" Introduction # We know Cycles is a pain in the butt to render. Specifically, the long render times. Of course, there\u0026rsquo;s tons of videos that talk about what settings to use, but those videos don\u0026rsquo;t explain what the settings do. So, exactly what settings do what?\nSamples # What are samples? In a nutshell, samples are rays, and the sample count represents how many rays are released by Cycles per pixel+ of the camera (yes Cycles starts from the camera as an optimization, all optical systems can be reversed).\n+ Note: the per pixel thing is why higher resolutions take longer to render compared to lower resolutions. More pixels means more rays for your computer to deal with\nJust understanding how Cycles works helps to understand how the rest of the settings to work.\nSo how is noise produced?\nWell when Cycles spews rays like a toddler, those rays have to eventually meet a light source. This is called convergence, and the better rays can \u0026ldquo;converge\u0026rdquo; with light sources, the less noise the render will have. That\u0026rsquo;s why bright scenes tend to have way less noise then dark scenes.\nBut when your scene doesn\u0026rsquo;t allow for rays to converge easily, you need more samples (or rays) to make up for the bad convergence+\n+ You could also make the scene brighter and reduce the exposure to make it darker, that's pretty common\nHere\u0026rsquo;s a totally amazing diagram explaining what I mean\nHere, we have a bunch of rays converging with the light source, but some also miss and go to the void.\nSo now we understand how samples work, and why darker scenes tend to have less noise, so let\u0026rsquo;s move on\nSidenote: You've probably heard of features like adaptive sampling and light portals. I personally think Blender's docs are good enough to explain these 2 features, as long as you understand how samples work. We can explain these features at a later date\nLight bounces # \u0026ldquo;Wait, rays don\u0026rsquo;t bounce infinitely?\u0026rdquo;\nWell, in the real world they do, and ideally a good path tracing engine would also, but no computer as of writing can handle the amount of processing power it takes, and we\u0026rsquo;re willing to approximate, so typically path tracing engines have a limit in the amount of bounces they perform per ray.\nIn a nutshell, light bounces are\u0026hellip; the amount of times a ray will bounce before converging (that fancy word again), if they can. There\u0026rsquo;s really 2 main settings to keep in mind\nTotal light bounces (how many bounces a ray can bounce in total) Material specific bounces (how many bounces can a ray bounce for a specific material) We\u0026rsquo;re not going to focus too much on this, since I think it\u0026rsquo;s self explanatory\nSidenote: You may also notice some caustics settings, as well as stuff like filter glossy. Caustics are patterns formed by reflection or reflection, whereas filter glossy allows for less noise (at the cost of accuracy).\nIn general, caustics should be disabled unless you have a reason not to, and filter glossy shouldn't be too high (a value of 1 is good enough for most scenes)\nHere\u0026rsquo;s a diagram (where we have a max of 3 bounces) Note how the red ray bounces 3 times (which is the max), but the black ray only needs 2. Total light bounces is well, the total amount of light bounces a ray can take.\nConclusion # \u0026ldquo;Wait, we\u0026rsquo;re already done?\u0026rdquo;\nFor now yes, I\u0026rsquo;ll be splitting this into multiple parts. What I\u0026rsquo;ve explained today should be enough for understanding how most of the settings in Cycles work. In later parts, I\u0026rsquo;ll be focusing on certain settings, like adaptive sampling or shadow caustics (oooooo, fancy). But we\u0026rsquo;ll leave it here for now.\n","date":"20 December 2022","externalUrl":null,"permalink":"/posts/2022/12/cycles-optimization-samples-and-bounces/","section":"Posts","summary":"","title":"Optimizing Render Times in Blender: Light Bounces and Samples","type":"posts"},{"content":"Hi guys, I think yall might be confused why I\u0026rsquo;ve created a new website, let\u0026rsquo;s talk about it.\nBut first, what\u0026rsquo;s been going on recently?\nWell in short, chaos. The actual situation is much longer, but to put it simply Twitter is no longer (in my opinion) a sustainable platform to remain on, so I moved to Mastodon.\nNow because Mastodon allows you to verify your own sites, I\u0026rsquo;ve gone ahead and made this new one, since I felt like it.\nOf course, some of you may have also noticed that I\u0026rsquo;m not really doing much 3D. In short, I haven\u0026rsquo;t had much time or motivation to continue working on 3D (but I\u0026rsquo;m getting there, hopefully I\u0026rsquo;ll think of something for New Years). I think I\u0026rsquo;ll try this blogging thing for a bit (I did want to make some in depth guides to Cycles optimization and MCprep itself).\nI\u0026rsquo;m also learning how this Hugo thing (what I use to make this) works, so hopefully I\u0026rsquo;ll be able to get my renders back up and running. It\u0026rsquo;ll be a pain and a hassle, but I think it\u0026rsquo;ll be worth it.\n","date":"19 December 2022","externalUrl":null,"permalink":"/posts/2022/12/moving-on/","section":"Posts","summary":"","title":"Moving On","type":"posts"},{"content":" Introduction # Hi there! If you\u0026rsquo;re reading this, you might be asking yourself, “what can a Minecraft artist teach about lighting?”. Before you close your browser, though, I want you to think of this not as a guide, but a collection of tips from my years of doing Blender. Ok, let\u0026rsquo;s continue.\nLighting may seem like something simple, but it gets complicated real fast. Simply moving a light a couple of centimeters (scene wise) can completely change how the resulting render feels to the viewer. Most people, however, seem to treat lighting as just something to get through, something to just edit in compositing.\nI personally believe that one\u0026rsquo;s lighting should be 90% of the way to the final render, hence this “guide” on how to improve one\u0026rsquo;s lighting. In this \u0026ldquo;guide\u0026rdquo;, I\u0026rsquo;m going to go over how I handle stuff like environment lighting, character lighting, and maybe a little stylization along the way.\nSure, I may be a relatively small artist in the 3D landscape, but who said small artists don\u0026rsquo;t have experience. Without further ado, let\u0026rsquo;s get started.\nWhy Light? # This is a question most of us forget to ask: why should we light our scenes in the first place?\nThere are multiple answers. The first one is depth. Without light, there\u0026rsquo;s no shadow, and without shadow, there is no depth.\nFor example, which one looks 3D? You might say the second image, but why? Because the second image has some form of depth from a gradient. A pretty big difference, and we haven\u0026rsquo;t even gotten into positioning lights yet.\nThere is a second reason, one that\u0026rsquo;s emphasized, but not explained: storytelling. Let me explain.\nA Sphere\u0026rsquo;s Story # Take this simple scene, what information does the lighting convey?\nThe lighting makes it clear that it\u0026rsquo;s day time. Here\u0026rsquo;s the same scene, but with a change in the light color and strength:\nNow we can assume it\u0026rsquo;s night. And what about this?\nWell, the sphere\u0026rsquo;s house is on fire and maybe the sphere is contemplating their life choices. And all we did was add another light source.\nSo clearly, lighting can make a big difference when it comes to story telling, and we\u0026rsquo;ve barely scratched the surface.\n","date":"5 June 2022","externalUrl":null,"permalink":"/lighting-guide/introduction/","section":"Lighting Guide","summary":"Introduction and why do we light scenes in the first place?","title":"Introduction and Why We light","type":"lighting-guide"},{"content":"","date":"5 June 2022","externalUrl":null,"permalink":"/series/lighting-guide/","section":"Series","summary":"","title":"Lighting Guide","type":"series"},{"content":"This is a lighting guide I made in early 2023. It used to be a PDF on Gumroad, and is now availible on my website!\n","date":"5 June 2022","externalUrl":null,"permalink":"/lighting-guide/","section":"Lighting Guide","summary":"","title":"Lighting Guide","type":"lighting-guide"},{"content":"I think the best way to explain my point is to show a practical example, so I\u0026rsquo;ve set up a scene that we\u0026rsquo;re going to build together. The goal is to end up with something like this:\nSo let\u0026rsquo;s get started. Here\u0026rsquo;s what we currently have:\nI\u0026rsquo;ve gone ahead and added some basic environment lighting. This can be done in many ways, from adding an HDRI to adding light sources based on an existing scene. While I won\u0026rsquo;t go over what I did in detail, I will introduce a fundamental law in environment lighting (and lighting in general):\n“If it\u0026rsquo;s off camera, do whatever the f-ck you want\u0026quot; - The Off Camera Law\nWe don\u0026rsquo;t really have much lighting right now, just from the environment, so let\u0026rsquo;s think about what type of story we want to tell. Clearly the character is thinking about something, maybe while out in the city on a sidewalk.\nWhile writing this, I realized that I could have gone a completely different direction with the lighting. Looking over the screenshots again reminded me of the opening of the trailer for Westside Story (specifically the 2021 version), which would have been really interesting in terms of using shadow.\nThat\u0026rsquo;s one of the things I like about lighting, there\u0026rsquo;s many ways to go about lighting the same scene. As such, I\u0026rsquo;ve decided to add another (albiet shorter) section on the other way we could go about lighting this scene in [[#What about a Different Way?]]\nWith that, let\u0026rsquo;s add a streetlamp:\nLooks decent, and we could leave it like that, but I want to make the light a bit more… streetlamp-ish, so let\u0026rsquo;s use an IES texture.\nIES textures are textures that represent light falloff. They\u0026rsquo;re an amazing tool, and honestly I think they make a good replacement for spot lamps, but that\u0026rsquo;s just me.\nOnce we add an IES texture and change the brightness, we get something like this:\nYou can find IES textures anywhere, just search on Google. I find IES Library to be a good source.\nGood start, let\u0026rsquo;s move on.\nSculpting With Light # Now we could leave it like this, but it\u0026rsquo;s not that interesting. One particular skill in lighting is “sculpting” the outline of your subject with light.\nI call it sculpting because it\u0026rsquo;s the process of making the subject stand out from the background, but you can call it whatever! Just make sure that it helps you remember the goal of what we do in this section.\nFor this example, we\u0026rsquo;re going to completely separate the character from the background, but you could also partially leave a subject in darkness. Again, it all goes back to storytelling, and the type of story you want to tell!\nLet\u0026rsquo;s first add an area light to highlight one of the edges of the head:\nWell, that didn\u0026rsquo;t make that much of a difference, and that\u0026rsquo;s because of a feature area lights have called “Beam Spread”\nBy default, it\u0026rsquo;s set to 180, which is extremely diffuse. Let\u0026rsquo;s reduce that: ![[Sculpting With Light/Reduced Spread.jpg]]\n“What\u0026rsquo;s the point of beam spread?\u0026quot;\nBeam spread can be useful when you want to control how soft or hard your shadows are without adjusting the size of the actual light itself. It allows an area light to act like a soft box basically.\nNow let\u0026rsquo;s add some extra lights to highlight the left arm/shoulder: Now this is getting boring, it\u0026rsquo;s all one color. This is supposed to be a city with a lot of neon lights, so let\u0026rsquo;s add another one (remember The Off Camera Law?):\nYeah, that doesn\u0026rsquo;t look good, it just looks like something from the background. What if we turn it into an area light?\nA bit too powerful, and reducing the strength doesn\u0026rsquo;t seem to help. What if we make it a small point light and use it to sculpt out another part of the head?\nStill no, is there any other way to add a second col- OH, kick light:\n“What is kick light?\u0026quot;\nKick light is a bit hard to define, but basically helps to add some “shaping” to the subject. One could argue that technically the light in this scene isn\u0026rsquo;t a kick light, but I digress.\nLet\u0026rsquo;s reduce the strength and add a pink one for some extra variation:\nAlright, we\u0026rsquo;re getting somewhere!\nWe Need More STYLE # Obviously since this is 3D, we can do whatever we want. In fact, alongside the Off Camera Law, there\u0026rsquo;s another law in 3D:\n“3D has no limits, except for your software\u0026rsquo;s limits, so do whatever makes your scene look good” - The No Limits Theorem\nSo let\u0026rsquo;s add a rim light:\nOf course, we have some volumetrics in the scene (maybe you noticed earlier) so we need to disable volumetrics for this light: Now I want to tweak this further, but I want this light to only affect the subject. Sadly, Blender doesn\u0026rsquo;t have light linking (seriously, why?), so we\u0026rsquo;re going to need to isolate this light on its own. Luckily, I have a light manager add-on (you can find them easily), so I can just do that with a single click: Looks mostly ok, we just need some rim lighting for the head: Let\u0026rsquo;s change the color too, maybe blue? Nah, red? Not feeling it, pink? Looks fine, let\u0026rsquo;s introduce everything else: Perfect, just need to adjust some of the rim lighting because that right arm is looking weird: I think we\u0026rsquo;re done!\nDon\u0026rsquo;t be scared to bend physics with light nodes for a stylized effect. Remember the No Limits Theorem, if it makes the scene look good, then it\u0026rsquo;s perfectly fine to bend physics the way you want\n","date":"4 June 2022","externalUrl":null,"permalink":"/lighting-guide/practical-example/","section":"Lighting Guide","summary":"Let\u0026rsquo;s go over how we can light a scene starting from scratch","title":"A Practical Example","type":"lighting-guide"},{"content":"Remember how I said while writing, I realized another route that could have been taken with this scene that involved heavy use of shadow? Well, I think I\u0026rsquo;ll quickly go over it (it\u0026rsquo;s not that long).\nWe\u0026rsquo;re aiming for something like this:\nWhile this route takes less steps, it\u0026rsquo;s easier to mess up with, not to mention that the results tend to be a lot darker with this method.\nFirst, let\u0026rsquo;s start with the basic sea lantern lighting we did in [[#A Practical Example]]:\nNow let\u0026rsquo;s add an array of skinny cubes and behind them, an area light:\nThis is a great oppertunity to take advantage of Beam Spread for softer shadows!\nNext, lets add some basic rim lights:\nAnd finally, let\u0026rsquo;s add a very basic kick light behind the subject to add some extra shaping and to make the scene a little brighter:\nI think we\u0026rsquo;re done!\nSince this section is on alternative routes, I highly suggest looking for even more ways to use light to tell the story you want to tell. I\u0026rsquo;ve gone over 2 here, but I bet that you can think of a 3rd or even a 4th way of lighting this scene! That\u0026rsquo;s one of the neat things about lighting, there\u0026rsquo;s multiple ways to go about telling your story.\n","date":"3 June 2022","externalUrl":null,"permalink":"/lighting-guide/a-different-way/","section":"Lighting Guide","summary":"Let\u0026rsquo;s go over another way we can light this scene, this time using shadow","title":"What About a Different Way?","type":"lighting-guide"},{"content":"We\u0026rsquo;ve gone over how to go about lighting, but what about deconstructing an existing lighting setup? It\u0026rsquo;s actually simpler than you think.\nSimple Example # Let\u0026rsquo;s start with the following scene: Here I\u0026rsquo;ve already constructed a lighting setup with 3 lights (yes, 3 lights). Firstly, we got our main light: It\u0026rsquo;s not that bad, but we’re losing a lot of details in the shadows. Sometimes that might be a good thing (depending on what type of story you\u0026rsquo;re telling) but in this case, we don\u0026rsquo;t want that. That\u0026rsquo;s why we also have a rim light: Now we\u0026rsquo;re getting some of the details we were loosing, but we could do with a little more sculpting. That\u0026rsquo;s where the kick light comes in: I should highly emphasize how this time, the kick light is not an area light. For the purposes of this render, a point light makes the perfect kick light.\nIf we combine it back with the rim light, we get some nice results: An Aside: Bounce Lighting # This scene also makes for a good example of bounce lighting and how much of an impact it has on how a scene looks. Let\u0026rsquo;s revisit how it currently looks: Now let\u0026rsquo;s change the background to be green: Yeah… that doesn\u0026rsquo;t look right, and all we did was change the color. Meanwhile, if we change it to red: Doesn\u0026rsquo;t look bad, but the overall vibe has changed in a way that I don\u0026rsquo;t like (although I bet some people would actually prefer this over the original).\nA More Complex Example # I think it\u0026rsquo;s now time to introduce something a bit more complex, so here we go.\nWe\u0026rsquo;re going to start with the following: This is a very simplified overview; the scene in question is extremely complex.\nFirst off, we got the light from the giant hologram statue (not Ferris the Rust mascot, the purple hologram on the right): That\u0026rsquo;s already a lot of light being provided, and this is on top of the environment lighting: That\u0026rsquo;s… bright. Most of it is to highlight the chaos of the city (hey, third year of the 2020s, it\u0026rsquo;s been hectic), but now we can move on to the subject: This is actually 2 lights, one simple area light with a blackbody node that serves as the main light: And one kick light to highlight some of the extra details that otherwise would be missing (like the hair and the sides of the glasses), as well as give more shape to the tail: ![](Deconstruct/Complex/Subject Back.jpg)\nThe kick light is also a different color, to make things a little more interesting.\nWas that extremely simplified? Yes, but this simplified approach helps when dealing tons of light sources, since they can generally be categorized in a couple of groups.\nIf you\u0026rsquo;re able to, study how others set up their lighting setups. Granted, you may not have access to their files, but you could likely figure out how a certain effect was made. And if you can\u0026rsquo;t, just ask! Most artists don\u0026rsquo;t mind being asked, so take advantage.\n","date":"2 June 2022","externalUrl":null,"permalink":"/lighting-guide/lets-demolish-stuff/","section":"Lighting Guide","summary":"Let\u0026rsquo;s take some existing scenes and deconstruct the lighting","title":"Let's Demolish Stuff!","type":"lighting-guide"},{"content":"Was learning some lighting tips from a Minecraft artist that bad? Probably somewhat, but even if you learned nothing, I got you to read this series :D\nThere\u0026rsquo;s many other resources on learning how to master lighting, this is just one. I personally recommend Andrew Price\u0026rsquo;s series on lighting, as he goes in depth about more Blender specifics. In addition, Pixar\u0026rsquo;s Khan Academy course is also an amazing course on what I like to call “Light Theory”.\nI hope this “guide” will encourage you to go on a journey to master a skill that\u0026rsquo;s commonly forgotten about.\nCya!\n","date":"1 June 2022","externalUrl":null,"permalink":"/lighting-guide/conclusion/","section":"Lighting Guide","summary":"Concluding remarks","title":"Conclusion","type":"lighting-guide"},{"content":"\u003c!DOCTYPE html\u003e zen photon garden zen photon garden this is my private fork of zen photon garden for me to tinker around with it.\nOh no. Zen photon garden is an interactive raytracer art-toy for HTML5 browsers.\nBut it looks like your browser isn't supported!\nTry the latest version of Chrome or Firefox.\n(You'll need JavaScript, Canvas, Web Workers, and Typed Arrays.)\nDraw on me. Save PNG… Share link… • ↩Undo ↪Redo ×Clear • Diffuse Reflective Transmissive ↕Exposure Creator's blog / Original git Rays traced:0 • Speed:0 rays/sec ","externalUrl":null,"permalink":"/zenphoton/","section":"StandingPad's Corner","summary":"","title":"","type":"page"},{"content":"Originally made on the Erindale.XYZ server, I\u0026rsquo;ve since copied it here and cleaned it up to make it easier to share\nWarning: Intense amount of swearing used here\nThere\u0026rsquo;s 3 types of websites:\nWebsites with no JavaShit (like the Plan9 UNIX website) Websites with a very tiny amount of JavaShit where absolutely needed (like this website) Websites with a shit ton of JavaShit and won\u0026rsquo;t show any content if you have 3rd party JavaShit disabled The 3rd type, are what I fucking hate the most. Those stupid motherfucking websites that somehow get to the top of the search results but when I open them go \u0026ldquo;please enable JavaShit in your browser in order to view the content :)\u0026rdquo; like for fuck\u0026rsquo;s sake if you can show that message, you can show the whole goddamn webpage. Those are the same websites whose developers go \u0026ldquo;wait disabled people exist?\u0026rdquo; or \u0026ldquo;wait, dyslexic people prefer being able to use their own fonts?\u0026rdquo; as if it isn\u0026rsquo;t fucking 2024.\nThis also includes websites made with any GUI because seriously those things are as bloated as a fucking T-Rex, I absolutely hate those. Like ok, cool that you don\u0026rsquo;t want to fucking learn web technologies to make a website because you\u0026rsquo;re too lazy to, but guess what, I can\u0026rsquo;t fucking load your website because of whatever shit your GUI website generator uses. You don\u0026rsquo;t even need stuff like Wix and Google Sites at this point; I\u0026rsquo;m far from a web developer, and this entire website is made in markdown, converted to HTML with Hugo, and styled using a modified Hugo theme. And guess what, it\u0026rsquo;s fucking fast. I can go all the way to fucking Lahore in Pakistan, with some of the slowest internet speeds in the world (because it\u0026rsquo;s fucking Pakistan), and I\u0026rsquo;ll still be able to view this website will load as fast as it does in the US. And yes, I\u0026rsquo;ve fucking done that, and it\u0026rsquo;s true.\nALSO, WHY ON EARTH DO THOSE PAGES HAVE A SHIT TON OF LAYOUT SHIFTS, like have these developers never heard of the width and height properties in the image ta- oh wait, they haven\u0026rsquo;t, they use whatever the hottest JavaShit framework is out right now, they don\u0026rsquo;t give a shit about user experience. By the time those fucking piece of shit websites load on my phone and my finger presses a link, it goes to a completely different place then I fucking intended because the fucking layout shift occurs right when I place my finger on the link (looking at you GitHub and your fucking obsession with layout shifts)\nAlso, why the fuck are icons now made with fucking fonts, are they trying to give more stress to the already fucking stressed networks, like have they not heard of fucking SVGs or you know, NOT USING A FUCKING WEBFONT. ALSO, THEY ALL SOURCE THEIR FONTS FROM FUCKING GOOGLE FONTS, BECAUSE I GUESS INCLUDING THE FONT IN static IS NOT WHAT THE COOL KIDS DO. Like seriously, do all of y\u0026rsquo;all have 100 TB/s speeds, cause clearly you motherfuckers think everyone else has that speed. Guess what? WE. DON\u0026rsquo;T. ALL. HAVE. GOOD. INTERNET. You hear me? We don\u0026rsquo;t all have fucking 10 TB/s speeds, and we don\u0026rsquo;t give a shit about your 100 MB navigation bar. We just want to fucking view the fucking content.\n","externalUrl":null,"permalink":"/a-rant-about-javashit-heavy-websites/","section":"StandingPad's Corner","summary":"","title":"A Rant About JavaShit Heavy Websites","type":"page"},{"content":" Hey there, I\u0026rsquo;m Mahid Sheikh, a 3D artist and developer from the Dallas-Fort Worth metroplex in Texas. I\u0026rsquo;m also a Pakistani-American (born in the US) and an Muslim. My main area is Minecraft rendering, and I work on the MCprep addon for Blender. In addition, I also maintain the Flatpak package for Bforartists. Outside of 3D rendering and programming, I play the flute (played for my local high school marching band), do some photography, or read.\nA bit boring, I\u0026rsquo;m aware.\n3D art work # My main area of work is Minecraft rendering. My main piece of software is Blender, though I also gained Revit certification in May of 2023.\nProfessional Work # Here\u0026rsquo;s some of the work I\u0026rsquo;ve done professionally.\nRelease artwork for MCprep 3.5 # MCprep is a workflow addon for Minecraft artists working in Blender, and I work as one of the maintainers of the project. Normally, we\u0026rsquo;d hold a contest with the community, but due to short notice, I was asked to make the release artwork for MCprep 3.5.\nRelease splash for MCprep 3.5 Work I\u0026rsquo;ve done in My Spare Time # This is a curated selection of work I\u0026rsquo;ve done in my spare time. As mentioned earlier, my main focus is Minecraft rendering, but I\u0026rsquo;ve also dabbled a little in ArchViz rendering in the past.\nClick an image to expand\nMajor Pieces # Since December 2023, I\u0026rsquo;ve been doing 2 major pieces a year, one on summer and one in winter, noted with a black border. These are pieces where I try and break my limits, and demonstrate what I\u0026rsquo;ve learned in the past several years. Here\u0026rsquo;s the major pieces from the past 2 years.\nAs a bit of a nerdy easter egg, the black border has a slight noise to the value of the original hex value (#171717), using the GnuIMP HSV noise filter, with the noise driven by the following 2 equations: $$ v(a, b, c) = sin(a+b+c) $$ $$ s(x, y, z) = sin(x) + sin(xy) + sin(xz) $$\nMeaning the border is unique per image.\n2024 # This piece was made for the summer of 2024. Unlike most of my work, this uses the Kuwahara filter to emulate a painting look. View in original resolution 2023 # 2023 only had one major piece, the winter piece for New Years, and doesn't use noise from the above equations. View in original resolution Development Experience # I\u0026rsquo;m not only a 3D artist but also a programmer. My main languages are:\nPython C++ Rust Additionally, I have experience with:\nHaskell Go Lua Bash Development Work # My main development work encompasses multiple areas, but these days it\u0026rsquo;s in addons that improve users workflows and contributing to open source projects in eneral. I\u0026rsquo;m one of the maintainers for the MCprep addon, a Blender addon that speeds up the workflow of Minecraft animators by providings tools such as material generation, importing premade rigs, creating automatic weather effects, and more, all with the click of a button. Moo-Ack-Productions/MCprep Blender python addon to increase workflow for creating minecraft renders and animations Python 274 26 In my MCprep career, I also created BpyBuild for the MCprep project. BpyBuild a program that aims to streamline the process of building Blender addons and automatically installing them to the targeted Blender versions, allowing developers to perform less mundane tasks and more development. Moo-Ack-Productions/bpy-build A build sytem to make building Blender addons 10 times easier Python 5 2 I\u0026rsquo;m also the maintainer of the Bforartists Flatpak package. Bforartists is a fork of Blender focused on improving the GUI experience for users, and I maintain the Flatpak build for Linux users who either prefer Flatpak or can only use a Flatpak version. flathub/de.bforartists.Bforartists null 2 1 And recently in 2024, I created a new addon called Estella, which streamlines light linking and light groups by using improved UX. StandingPadAnimations/Estella Streamline working with light groups and linking! Python 1 0 Contact # Interested? Contact me at contact@standingpad.org\nResume can be found here\nUnsoliciated advertisements will result in me blocking your email address and adding it to a public list of all email addresses blocked here, so please do not send me advertisements though email.\n","externalUrl":null,"permalink":"/about/","section":"StandingPad's Corner","summary":"","title":"About Me","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"This is a list of all email addresses that have sent me adverts or spam in the past to my email address (contact@standingpad.org), and as such have been blocked.\nIf your email is on here, shame on you. On the bright side, you can tell your parents you\u0026rsquo;re such a jerk that you\u0026rsquo;ve achieved the most recognition you\u0026rsquo;ll ever receive in your lives.\nComplete list # akhileshpathak1@outlook.com reetuchaudhary@aol.com christianraymondk@gmail.com meenusingh4586@outlook.com surbhiwebso@gmail.com vinaytiwariofficial3@gmail.com munasingh24@outlook.com evalong1990@gmail.com George.Harrison88@hotmail.com DavidTucker915P@hotmail.com RichardDagres@outlook.com Durga_prasad_Seo@hotmail.com sonasingh44@outlook.com anjaliroy70@outlook.com manojseoservice@outlook.com ankitkrpanday37@outlook.com Durga_prasad_Seo@hotmail.com yogesh@itwebapp.in singhshephali549@gmail.com lakshmisingh34@outlook.com Fabianallen88880@outlook.com service@cb4c63617d.nxcli.io PaulaCole518@outlook.com RaviChourasia1366@outlook.com paulacole518@outlook.com binitakumari24@outlook.com sonamverma_seo_smo@outlook.com contact@nwjgc.biz samira6pqw@gmail.com abhisahaniaaaa@gmail.com sangeetamobileshop@outlook.com okx7@712e52eb5e.nxcli.io metamask83347@2fa.io contact@ezkel.com shalinsharma32@gmail.com amiepollack@joinbackdropbuild.com emily.m@buysocials.org Suman-SinghSEOservice@outlook.com tanvisingh6pw@gmail.com Poonam-SEO@hotmail.com abhijeetsingh2016@outlook.com james@topsolarleads.com App Developers # These are people who emailed me with offers to make apps. I don\u0026rsquo;t have a reason for an Android or iOS app, so don\u0026rsquo;t bother emailing me.\nakhileshpathak1@outlook.com RichardDagres@outlook.com Durga_prasad_Seo@hotmail.com anjaliroy70@outlook.com manojseoservice@outlook.com ankitkrpanday37@outlook.com Durga_prasad_Seo@hotmail.com RaviChourasia1366@outlook.com abhijeetsingh2016@outlook.com Web Designers and Brand Promoters # These are people who emailed me with web design and brand promoting offers. If you\u0026rsquo;re a web designer or a brand promoter, don\u0026rsquo;t email me, I\u0026rsquo;m not interested. I know you\u0026rsquo;re all from India and use bots (because otherwise my analytics service would be telling me I\u0026rsquo;m doing well based on the amount of emails I get) to grab emails from websites and spam the crap out of people.\n\u0026ldquo;But I know Wordpress\u0026rdquo; - This website doesn\u0026rsquo;t use Wordpress. \u0026ldquo;But SEO\u0026rdquo; - I actually care about my content. \u0026ldquo;I know JS\u0026rdquo; - You mean using JavaScript frameworks that add gigabytes of bloat? \u0026ldquo;I can improve your website\u0026rdquo; - I know for a fact you\u0026rsquo;ve never seen it with your own eyes, unless you\u0026rsquo;ve somehow evaded analytics 10^10 times. \u0026ldquo;Let us increase your profits\u0026rdquo; - 0 times 100 is still 0\nAlso if you address me as \u0026ldquo;Domain Owner\u0026rdquo;, that\u0026rsquo;s automatically means you don\u0026rsquo;t care enough to actually dig around the website and learn about who I am, so why should I care about you?\nJust shut up, I\u0026rsquo;m not interested.\nreetuchaudhary@aol.com christianraymondk@gmail.com meenusingh4586@outlook.com surbhiwebso@gmail.com vinaytiwariofficial3@gmail.com munasingh24@outlook.com evalong1990@gmail.com George.Harrison88@hotmail.com DavidTucker915P@hotmail.com sonasingh44@outlook.com yogesh@itwebapp.in singhshephali549@gmail.com lakshmisingh34@outlook.com Fabianallen88880@outlook.com paulacole518@outlook.com binitakumari24@outlook.com sonamverma_seo_smo@outlook.com contact@nwjgc.biz samira6pqw@gmail.com abhisahaniaaaa@gmail.com sangeetamobileshop@outlook.com shalinsharma32@gmail.com emily.m@buysocials.org Suman-SinghSEOservice@outlook.com tanvisingh6pw@gmail.com Poonam-SEO@hotmail.com james@topsolarleads.com Crypto Scams # I may be playing around with Monero, but I don\u0026rsquo;t use crypto services, so these are clear scams.\nservice@cb4c63617d.nxcli.io okx7@712e52eb5e.nxcli.io metamask83347@2fa.io General Phishing Scams # Most of these people are stupid and say \u0026ldquo;Dear Domain Owner\u0026rdquo; instead of addressing me by name.\ncontact@ezkel.com Unsolicited Advertisements # My email is not for advertisement junk, it\u0026rsquo;s for actual correspondence.\namiepollack@joinbackdropbuild.com FAQ # Q: Please remove me! A: No, you chose to send bullcrap to my email, you\u0026rsquo;re not getting off of this wall of shame.\n","externalUrl":null,"permalink":"/email-shame-list/","section":"StandingPad's Corner","summary":"","title":"Emails that have done Shameful Behavior","type":"page"},{"content":"For many beginning artists, it\u0026rsquo;s hard to imagine that the people you look up to were once beginners too. In addition, it\u0026rsquo;s easy for experienced artists like myself to feel a bit of impostor syndrome at our work and forget how far we\u0026rsquo;ve gone, so I\u0026rsquo;ve created this page of my growth over the years.\nIt\u0026rsquo;s a bit embarrassing (especially 2020-2021/22), but every artist feels that way about their old work.\nThis is not by any means an exhaustive list of everything I\u0026rsquo;ve made, this is just a couple of highlights that I think encapsulate what I\u0026rsquo;ve done this year.\nPS: I highly apologize for the bad image layouts, so I\u0026rsquo;ve added a table of contents to make it easier to navigate.\n2020 # First year of Blender\u0026hellip; for a bit of context, Songs of War was still a big thing at this time, and was one of the reasons I started Blender. Well, if I\u0026rsquo;m being truthful, I just saw a cool Minecraft rig on Twitter (Thomas Animations Rig). Didn\u0026rsquo;t know what Blender was, but I downloaded it (I\u0026rsquo;m a bit of a file hoarder, I know) to play around with it. Ironically I\u0026rsquo;m not a big fan of the rig, but I have to thank it for starting my 3D art career.\nIf I\u0026rsquo;m being honest however, these few pieces that I\u0026rsquo;ve selected don\u0026rsquo;t truly encapsulate my mental state at the time. In past blog posts, I\u0026rsquo;ve mentioned that around winter things for me get\u0026hellip; depressive, but between 2020-2021, it was far worse, and that manifested in some of my works (many of which I haven\u0026rsquo;t found at the time of writing). So when I say I\u0026rsquo;m grateful for the support I was given by the community, I truly mean it, even if seem distant or critical at times.\n2021 # This was when my style started to develop a little more, and also when I stopped doing Songs of War related pieces since I didn\u0026rsquo;t feel motivated to make any more. There\u0026rsquo;s really not much I have to say about 2021/\n2022 # This was really when my style started to become more consistent, as well as use female characters for pieces. However, towards the end, I started having art-block, something that\u0026rsquo;ll play a big part of how 2023 goes.\n2023 # This was a year of intense art-block for me, so there really isn\u0026rsquo;t much that I have.\nI began doing what I call \u0026ldquo;micro-detailing\u0026rdquo;, where I add extra details in the materials, but leave the overall render in a Minecraft style. Sometime in the middle of the year, I finished my custom, in-house rig. Here\u0026rsquo;s some stuff using that new rig. ","externalUrl":null,"permalink":"/growth/","section":"StandingPad's Corner","summary":"","title":"Growth","type":"page"},{"content":" Analytics # StandingPad.org measures page traffic with GoatCounter, which is open source under a modified version the European Union Public License. GoatCounter\u0026rsquo;s privacy policy goes in depth, but here\u0026rsquo;s the gist.\nEvery unique visitor is considered the same individual for 8 hours. Afterwards, GoatCounter will consider an individual to be a different person. Cookies are not used for analytics, only IP addresses (which are hashed when stored to reduce traceability), and all information is anonymized and can not be traced back to an individual for GDPR complience (see here for more details).\nNone of the information collected can be used to personally identify you No information is shared with 3rd parties All data is collected from the browser The following information is collected and retained:\nVisited Page Referrers (where the page was visited from) Screen size Browser, Operating system, Device (desktop, mobile, etc), and screen size Country and language We also respect the Do-Not-Track header, should you choose to enable it, and blockers such as Ublock Origin.\n","externalUrl":null,"permalink":"/privacy-policy/","section":"StandingPad's Corner","summary":"","title":"Privacy Policy","type":"page"},{"content":" All of my publically avalible resources. All Blend files are signed and can be verified using the following public key: 7F6A0E6FA332BAD0EC9E76B383C7F596A88BE583 keys.openpgp.org\nIf you use any of these assets, you must follow the terms of the BSD 3-Clause license\nBSD 3-Clause License Copyright (c) 2023-2024, Mahid Sheikh Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026quot;AS IS\u0026quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Lighting Series # Guide on how to approach lighting in Blender\nTo The Lighting Guide! RTX Style Water Shader V1 # An old water shader I made that emulates the look of water in RTX Minecraft.\nDownload Signature File RTX Style Water Shader V2 # My second attempt to make a RTX Minecraft style water shader, this time being much closer. If you\u0026rsquo;re interested in how I made it, I\u0026rsquo;ve linked the post where I talk about how I made it\nMaking a Minecraft RTX Style Water Shader in Blender: Attempt 2 22 June 2023\u0026middot;750 words Blender Download Signature File Principled Emission Shader # An emission nodegroup with more options, as well as brightness in lumens instead of watts\nDownload Signature File Custom Rig # Custom rig I created for my own use. Please keep the license in mind when using this rig Releasing My Custom Rig 26 September 2024\u0026middot;55 words Blender Download Signature File ","externalUrl":null,"permalink":"/resources/","section":"StandingPad's Corner","summary":"","title":"Resources","type":"page"}]